---
title: DCGAN
date: 2019-02-19 20:28:50
categories:
- Deep Learning
tags:
- Theory
- DCGAN
mathjax: true
---

参考：

> [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)
> [DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow)

DCGAN，全称 Deep Convolutional Generative Adversarial Networks，深层卷积生成式对抗网路，顾名思义，
它是一个GAN模型的同时必定使用了卷积神经网络的结构，最初的GAN是非监督学习的模型，但是CNN通常用于监督学习，这
两者如何结合，为什么可以实现非监督条件下对原始图像的学习，且看作者是如何论证的。

<!-- more -->

## 1. DCGAN作者说

首先作者肯定了GAN的功能：生成多样性样本，生成样本可以用于其他监督学习任务，判别器网络可以被用于一些分类任务（这里我觉得应该只能分真假，而不是分种类）。然后针对GAN训练过程中的常见问题：训练不稳定，提出了深层卷积的结构，最后对卷积核进行了可视化的研究，意图理解卷积核是如何学习到数据特征。

DCGAN的生成器网络结构如下所示，输入是长度为100的随机噪声，输出的是$64 \times 64$大小的图像。

{% asset_img DCGAN.png %}

DCGAN结构设计：

* 所有的池化层（pooling）都用卷积层替换，原因：池化在分类任务中的作用是提高卷积核的学习能力，使图像在短距离平移后依然保持原有特征结构，但是在生成器网络中，我们的目的是尽可能地学习原有数据的细节而不需要这种冗余，因此卷积层有利于在上采样过程中学习到数据特征，而对于判别器来说，与分类任务不同的地方在于判别器网络会影响生成器的训练效果，因此判别器也需要使用卷积层替换池化层；
* 生成器网络的输入是随机噪声$\mathbb{Z}$长度为100，但是并不是直接作为卷积的输入，需要先做矩阵乘法转换为一个4维张量；判别器最后一层通过Flatten然后输入一个Sigmoid分数；
* 判别器和生成器都在激活函数之前使用BatchNorm，但是生成器最后的输出层以及判别器的输入层不使用；
* 生成器激活函数维ReLU，输出层tanh；判别器激活函数为LeakyReLU，输出Sigmoid。

需要注意的是虽然论文图上第一层是$4 \times 4 \times 1024$，但是在很多实现的代码中是$4 \times 4 \times 512$









