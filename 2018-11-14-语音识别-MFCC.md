---
title: 语音识别-MFCC
date: 2018-11-14 09:13:33
categories:
- speech recognition
tags:
- theory
- MFCC
mathjax: true
---

参考：

[Spectrogram, Cepstrum and Mel-Frequency Analysis](http://www.speech.cs.cmu.edu/15-492/slides/03_mfcc.pdf)

《解析深度学习-语音识别实践》第1章 简介

> 语音识别过程：切除首尾端静音---声音划分为帧---对每一帧提取MFCC特征---若干帧对应一个状态---三个状态组成一个音素---若干音素组成单词

## 1. 语音识别系统的基本结构

语音识别系统主要由4个部分组成：信号处理和特征提取、声学模型（AM）、语言模型（LM）和解码搜索部分。

{% asset_img asr.png 语音识别系统架构 %}

* 信号处理和特征提取部分以音频信号为输入，通过消除噪声和信道失真对语音进行增强，将信号从时域转化为频域，并为后面的声学模型提取合适的有代表性的特征向量；
* 声学模型将声学和发音学的知识整合，以特征提取部分生成的特征作为输入，并为可变长特征序列生成声学模型分数；
* 语言模型估计通过从训练语料（通常是文本形式）学习词之间的相互关系，来估计假设词序的可能性，又叫语言模型分数；
* 解码搜索对给定的特征向量序列和若干假设词序列计算声学模型分数和语言模型分数，将总体输出分数最高的词序列当做识别结果。

在信号处理和特征提取部分，通常使用梅尔频率倒谱系数（MFCC）或者相对频谱变换-感知线性预测（RASTA-PLP）作为特征向量，这里是对MFCC进行说明。

<!-- more -->

## 2. 傅里叶变换

傅里叶变换是一种将时域信息转换为频域信息的函数，转换后的频域信息是基于三角函数`sin，cos`的复合函数，
理论上来说傅里叶变换可以拟合任意形式的时域函数图像，最终得到的频谱图就包含了所有成分的频率和振幅。

<!-- ![](2018-11-14-语音识别-MFCC/ft.gif) -->
{% asset_img ft.gif 语音识别系统架构 %}

由此可见，傅里叶变换在语音识别系统中非常实用，因为语音文件就是一个时域上的信息，我们将其映射到频域上可以得到关于声音更多的信息（音调/音色/响度？）

首先看一下傅里叶变换的公式

{% asset_img dft.jpg 傅里叶变换%}

以及傅里叶逆变换

{% asset_img idft.jpg 傅里叶逆变换%}

而声音文件理论上是一个连续函数，但是连续不好描述，我们将声音划分为一帧一帧，每一帧表示的时间长度与这个声音文件的格式相关（不同格式采样率不同，但都是`ms`级别），所以最终我们观察到的声音信息是离散的。

离散傅里叶变换

{% asset_img dtft.jpg 离散傅里叶变换%}

以及离散傅里叶逆变换

{% asset_img idtft.jpg 离散傅里叶逆变换%}

## 3. 声谱图Spectrogram

首先将声音文件划分为一帧一帧，然后对每一帧的信息做快速傅里叶变换FFT，得到频谱图，纵轴是振幅（如果对振幅取对数，那么单位为`dB`分贝），横轴是频率`Hz`

{% asset_img fft.png 离散傅里叶变换%}

将得到的频谱图旋转`90°`，再将振幅映射为灰度值，而这些灰度值较大的位置称为**共振峰**（Formants），**共振峰就是携带了声音的辨识属性**

{% asset_img map.png 映射%}

如果将每一帧的的灰度图连接起来，我们就得到了这段声音文件的声谱图

{% asset_img link.png 声谱图%}

一个真实数据的声谱图，从图中我们可以找出共振峰，而对应最上面的声音文件；声音不属于同一部分，那么共振峰的位置也不同；声音属于统一部份，则那些帧的共振峰基本相同。根据共振峰的位置我们可以实现声音的区分（不同声音通道/不同人/不同物种），以及对帧的合并，这些信息通过HMM有助于语音识别。

{% asset_img realdata.png 声谱图%}

## 4. 倒谱分析Cepstral Analysis

这是一帧声音文件，我们用点标注出振幅峰值点（**共振峰**），用线（**包络**）描述振幅变化过程，**我们的目的是提取出包络的信息**

{% asset_img formants.png 共振峰%}

对频谱进行分解，我们可以的到包络和细节，这里默认我们已经经过对数运算，所以只需要简单叠加就能通过包络和细节还原声音信息。同时根据图像变化情况，我们将横轴当作时间，则包络属于低频成分（变化慢），细节属于高频成分（变化快），那么只需要增加一个低通滤波器，我们就可以得到包络的输出，过滤掉细节。

{% asset_img detail.png 细节和包络%}

那么倒谱分析的过程为：

1. 语音信号经过傅里叶变换称为频谱
$$
X[k] = H[k]E[k]
\\
\left \| X[k] \right \| = \left \| H[k] \right \| \left \| E[k] \right \|，只考虑幅度
$$

2. 两边取对数

$$
\log{\left \| X[k] \right \|} = \log{\left \| H[k] \right \|} + \log{\left \| E[k] \right \|}
$$

3. 两边做傅里叶逆变换

$$
x[k] = h[k] + e[k]
$$

## 5. 梅尔频率分析Mel-Frequency Analysis

梅尔频率分析是基于人类听觉感知实验的，实验发现，如果将人耳表示为一个滤波器，那么这个滤波器的特点是在所有频率上不是均匀分布，在低频部分有更多的滤波器，在高频部分较少，并且只针对特定的某些频率有效。

{% asset_img filter.png 滤波器%}

梅尔频率倒谱系数（MFCC）考虑到了人类的听觉特征，先将线性频谱映射到基于听觉感知的梅尔非线性频谱中，然后转换到倒谱上，也就是说我们需要修改上面的步骤1，增加梅尔滤波器进行频谱映射

{% asset_img mel.png 滤波器%}

最终通过傅里叶逆变换，我们就可以获取到MFCCs特征。

总结一下步骤：

1. 先对语音进行预加重、分帧和加窗；（加强语音信号性能（信噪比，处理精度等）的一些预处理）

2. 对每一个短时分析窗，通过FFT得到对应的频谱；（获得分布在时间轴上不同时间窗内的频谱）

3. 将上面的频谱通过Mel滤波器组得到Mel频谱；（通过Mel频谱，将线形的自然频谱转换为体现人类听觉特性的Mel频谱）

4. 在Mel频谱上面进行倒谱分析（取对数，做逆变换，实际逆变换一般是通过DCT离散余弦变换来实现，取DCT后的第2个到第13个系数作为MFCC系数），获得Mel频率倒谱系数MFCC，这个MFCC就是这帧语音的特征；（倒谱分析，获得MFCC作为语音特征）

