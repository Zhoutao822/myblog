---
title: 线性模型-coding
date: 2018-11-07 22:00:56
categories:
- machine learning
tags:
- code
- linear model
mathjax: true
---

## 1. 数据集说明

### 1.1 线性回归数据集-Boston房价

* 数据来源：sklearn.datasets.load_boston（tensorflow.keras.datasets.boston_housing理论上应该是一模一样的）；
* 数据集形状：总计506个样本，每个样本由14个属性表示，一般将最后一个房价作为target，所有属性值均为number，详情可调用load_boston()['DESCR']了解每个属性的具体含义；
* 数据集划分：随机选出20%数据作为测试集，不做验证集要求；
* 性能度量：MSE或者RMSE均可以。

### 1.2

## 2. 线性回归

### 2.1 公式法

**我们先不考虑特征工程，仅将所有特征放入线性回归模型中**。

> 首先导入需要的第三方库

```python
from sklearn.datasets import load_boston #数据集
from sklearn import preprocessing #归一化处理
from sklearn.model_selection import train_test_split #数据集划分
import pandas as pd #观察数据集
import matplotlib.pyplot as plt #绘制图表
import numpy as np #数据处理
pd.set_option('precision', 2) #设置pandas显示数据保留两位小数
```

> 然后看看数据的大致范围与一些统计信息

```python
boston = load_boston() #加载数据，load_boston()返回的是一个字典
print(boston['DESCR']) #打印数据集描述信息

filepath = boston['filename'] #调用load_boston()会下载数据集csv文件到本地，通过filename获取路径
df = pd.read_csv(filepath, skiprows=0, header=1) #通过pandas读取csv文件，由于sklearn下载的csv文件第0行是样例数和属性数，第1行是属性名称，从第2行开始才是数据，所以设置skiprows跳过第0行，设置header特征行为1
df.describe() #显示数据集统计信息
```

{% asset_img boston.png linear %}

> 数据集划分

```python
data = boston['data'] #data对应前13列，即特征列，获取到的数据类型为np.array
target = boston['target'] #target对应最后一列，即目标列

x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, shuffle=True) #调用train_test_split划分数据集，指定test_size为0.2，指定shuffle为True，在划分前打乱数据集

# 注释掉的部分是对数据进行归一化处理，减去均值，再除以标准差，这个伏笔
# scaler = preprocessing.StandardScaler().fit(x_train)
# x_train_scale = scaler.transform(x_train)
# x_test_scale = scaler.transform(x_test)
# x_train_scale = np.column_stack((x_train_scale, np.ones(len(x_train_scale))))
# x_test_scale = np.column_stack((x_test_scale, np.ones(len(x_test_scale))))

x_train = np.column_stack((x_train, np.ones(len(x_train)))) #在公式法中我们还要增加一列全1为偏差bias
x_test = np.column_stack((x_test, np.ones(len(x_test))))
```

> 计算预测值与损失

```python
def standLR(x, y):
    '''
        根据公式计算参数w（已经包括bias）
    '''
    xMat = np.mat(x) #将np.array数据转成矩阵便于后续计算
    yMat = np.mat(y).T #对应一列

    xTx = xMat.T * xMat #.T实现矩阵转置
    if np.linalg.det(xTx) == 0.0: #如果矩阵行列式为0说明矩阵不可逆
        print('矩阵不可逆，请使用其他方法！！')
        return
    w = xTx.I * xMat.T * yMat #计算w，w的形状是一列
    return w

def predict(x, w):
    return np.mat(x) * w #根据w计算预测值，预测值也是一列

def mse(pre, y):
    m = y.shape[0]
    yMat = np.mat(y).T
    loss = np.sum(np.square(pre - yMat)) / m #计算MSE，也可以开方获取RMSE
    return loss

w = standLR(x_train, y_train)
pre = predict(x_test, w)
loss = mse(pre, y_test)
print('MSE for testSet is: {:.3f}'.format(loss))

#绘制预测值与真实值，以y=x为标准，越接近这条线越准确
plt.figure(figsize=(4, 4))
plt.plot([0, 60], [0, 60])
plt.scatter(pre.A, y_test)
plt.show()
```

> MSE for testSet is: 26.741 ，每次结果都不一定相同

{% asset_img standpre.png linear %}

* 当使用了归一化后的特征列数据进行求解时，我们最后得到的预测性能和没有使用归一化的是几乎一样的，但是这是不是意味着归一化没有用处呢，当然不是；
* 在不考虑特征工程的情形下，我们仅通过线性回归能得到的完美解$w$，在测试集上的损失是23.541，我们要想提高性能减少损失需要考虑特征工程或其他方法；
* 当样例数和特征数增大时，矩阵计算需要大量内存，这个方法不合适；
* 在标准线性回归中，我们没有考虑单个样本损失的权重，比如测试点与某些样本点距离很近，那么这些近距离的样本点的损失对测试点就应当更重要，所以它们的损失权重应该较大，而那些远离测试点的样本点，其权重应当较小，基于这个理论，我们使用局部加权线性回归测试一下。

### 2.2 局部加权线性回归LWLR

```python
def lwlr(x_point, x, y, k=1.0):
    '''
        Description：
            局部加权线性回归，在待预测点附近的每个点赋予一定的权重，在子集上基于最小均方差来进行普通的回归。
        Notes:
            这其中会用到计算权重的公式，w = e^((x^((i))-x) / -2k^2)
            理解：x为某个预测点，x^((i))为样本点，样本点距离预测点越近，贡献的误差越大（权值越大），越远则贡献的误差越小（权值越小）。
            关于预测点的选取，在我的代码中取的是样本点。其中k是带宽参数，控制w（钟形函数）的宽窄程度，类似于高斯函数的标准差。
            算法思路：假设预测点取样本点中的第i个样本点（共m个样本点），遍历1到m个样本点（含第i个），算出每一个样本点与预测点的距离，
            也就可以计算出每个样本贡献误差的权值，可以看出w是一个有m个元素的向量（写成对角阵形式）。
    '''
    xMat = np.mat(x)
    yMat = np.mat(y).T
    x_point = np.mat(x_point)
    m = np.shape(xMat)[0]
    weights = np.mat(np.eye(m))     # eye()返回一个对角线元素为1，其他元素为0的二维数组，创建权重矩阵weights，该矩阵为每个样本点初始化了一个权重
    for j in range(m):
        diff = x_point - xMat[j, :]         # 计算 testPoint 与输入样本点之间的距离，然后下面计算出每个样本贡献误差的权值
        # print(diff * diff.T)
        weights[j, j] = np.exp(diff * diff.T / (-2.0 * k**2))
        # print(weights[j, j])
    xTx = xMat.T * (weights * xMat)     # 根据矩阵乘法计算 xTx ，其中的 weights 矩阵是样本点对应的权重矩阵
    if np.linalg.det(xTx) == 0.0: #如果矩阵行列式为0说明矩阵不可逆
        print('矩阵不可逆，请使用其他方法！！')
        return
    w = xTx.I * (xMat.T * (weights * yMat))
    return x_point * w

def lwlrPre(x_test, x, y, k=1.0):
    m = x_test.shape[0]
    pre = np.mat(np.zeros((m, 1)))
    for i in range(m):
        pre[i] = lwlr(x_test[i], x, y, k)
    return pre
# 这里使用了归一化后的数据，因为没有归一化的样本的diff值很大，导致exp运算后的值接近0，最后导致矩阵行列式为0
pre = lwlrPre(x_test_scale, x_train_scale, y_train, k=1.1)
loss = mse(pre, y_test)
print('MSE for testSet is: {:.3f}'.format(loss))

plt.figure(figsize=(4, 4))
plt.plot([0, 60], [0, 60])
plt.scatter(pre.A, y_test)
plt.show()
```
> MSE for testSet is: 7.435 ，每次结果都不一定相同，但是效果明显优于标准线性回归

{% asset_img lwlrpre.png linear %}

### 2.3 岭回归

```python
def ridgeRegress(x, y, lam=0.2):
    '''
        Desc：
            这个函数实现了给定 lambda 下的岭回归求解。
            如果数据的特征比样本点还多，就不能再使用上面介绍的的线性回归和局部现行回归了，因为计算 (xTx)^(-1)会出现错误。
            如果特征比样本点还多（n > m），也就是说，输入数据的矩阵x不是满秩矩阵。非满秩矩阵在求逆时会出现问题。
            为了解决这个问题，我们下边讲一下：岭回归，这是我们要讲的第一种缩减方法。
    '''
    xMat = np.mat(x)
    yMat = np.mat(y).T
    xTx = xMat.T * xMat
    demon = xTx + np.eye(xMat.shape[1]) * lam     # 岭回归就是在矩阵 xTx 上加一个 λI 从而使得矩阵非奇异，进而能对 xTx + λI 求逆
    if np.linalg.det(xTx) == 0.0: #如果矩阵行列式为0说明矩阵不可逆
        print('矩阵不可逆，请使用其他方法！！')
        return
    w = xTx.I * (xMat.T * yMat)
    return w
# 由于我们使用的数据集不存在特征比样本点还多的情况，因此岭回归未起作用
w = ridgeRegress(x_train_scale, y_train, lam=0.2)
pre = predict(x_test_scale, w)
loss = mse(pre, y_test)
print(loss)

plt.figure(figsize=(4, 4))
plt.plot([0, 60], [0, 60])
plt.scatter(pre.A, y_test)
plt.show()
```
> MSE for testSet is: 26.741 ，每次结果都不一定相同

{% asset_img standpre.png linear %}

### 2.4 梯度下降

使用梯度下降可以避免公式法面临的内存消耗问题

**基于Tensorflow框架实现线性回归**

1. 使用Tensorflow提供的LinearRegressor

```python
#coding=utf-8

import tensorflow as tf
import numpy as np
from tensorflow.keras.datasets import boston_housing
from sklearn import preprocessing
# 默认划分20%的测试集
(x_train, y_train), (x_test, y_test) = boston_housing.load_data()

# 注释掉的部分对数据进行归一化处理，可以加速收敛
# scaler = preprocessing.StandardScaler().fit(x_train)
# x_train = scaler.transform(x_train)
# x_test = scaler.transform(x_test)

# 这里是为了适配LinearRegressor需要的feature_columns，而feature_columns指定了参与训练的特征，我们可以直接增加或减少feature_columns来比较在不同特征数下模型的性能
# 把每一列数据保存为一个键值对，键的名称来源数据集说明
def createDict(X):
    return {
        'CRIM': X[:, 0].ravel(),
        'ZN': X[:, 1].ravel(),
        'INDUS': X[:, 2].ravel(),
        'CHAS': X[:, 3].ravel(),
        'NOX': X[:, 4].ravel(),
        'RM': X[:, 5].ravel(),
        'AGE': X[:, 6].ravel(),
        'DIS': X[:, 7].ravel(),
        'RAD': X[:, 8].ravel(),
        'TAX': X[:, 9].ravel(),
        'PTRATIO': X[:, 10].ravel(),
        'B': X[:, 11].ravel(),
        'LSTAT': X[:, 12].ravel(),
    }

# 在这里控制参与训练的特征列
feature_columns = []
for key in createDict(x_train).keys():
    feature_columns.append(tf.feature_column.numeric_column(key=key))

# estimator的输入数据是一个dataset模式，具体可以上官网了解
def input_train():
    dataset = tf.data.Dataset.from_tensor_slices((createDict(x_train), y_train))
    dataset = dataset.shuffle(1000).batch(64).repeat() # 数据集打乱/batch/重复
    return dataset.make_one_shot_iterator().get_next()

def input_test():
    dataset = tf.data.Dataset.from_tensor_slices((createDict(x_test), y_test))
    dataset = dataset.shuffle(1000).batch(64)
    return dataset.make_one_shot_iterator().get_next()

# LinearRegressor的参数还可以指定优化器、参数正则化等等
model = tf.estimator.LinearRegressor(
    feature_columns=feature_columns, # 指定特征列
    model_dir="C://Users//Admin//Desktop//model" # 指定模型保存的位置，包括了checkpoint和tensorboard数据
    )

model.train(input_fn=input_train, steps=20000) # 开始训练模型，steps指定训练次数，每一次消耗一个batch的数据，进行一次参数更新

model.evaluate(input_fn=input_test) # 使用测试集数据评估模型性能，若使用的是同一组训练集和测试集，那么梯度下降最终得到的损失应该不低于直接用公式法得到的损失
```

2. 使用Tensorflow的eager模式

3. 使用Tensorflow的graph模式

## 3. 二分类sigmoid



## 4. 多分类softmax



## 5. LDA降维