---
title: 线性模型-coding
date: 2018-11-07 22:00:56
categories:
- machine learning
tags:
- code
- linear model
mathjax: true
---

## 1. 数据集说明

### 1.1 线性回归数据集-Boston房价

* 数据来源：sklearn.datasets.load_boston（tensorflow.keras.datasets.boston_housing理论上应该是一模一样的）；
* 数据集形状：总计506个样本，每个样本由14个属性表示，一般将最后一个房价作为target，所有属性值均为number，详情可调用load_boston()['DESCR']了解每个属性的具体含义；
* 数据集划分：随机选出20%数据作为测试集，不做验证集要求；
* 性能度量：MSE或者RMSE均可以。

### 1.2 二分类数据集-乳腺癌

* 数据来源：sklearn.datasets.load_breast_cancer；
* 数据集形状：总计569个样本，良性357个，恶性212个，每个样本由30个属性表示，target表示肿瘤良性1还是恶性0，所有属性值均为number，详情可调用load_breast_cancer()['DESCR']了解每个属性的具体含义；
* 数据集划分：随机选出20%数据作为测试集，不做验证集要求；
* 性能度量：accuracy或ROC。

### 1.3 多分类数据集-鸢尾花

* 数据来源：sklearn.datasets.load_iris；
* 数据集形状：总计150个样本，一共3种花，每种50个，每个样本由4个属性表示，target表示花的种类0/1/2，所有属性值均为number，详情可调用load_iris()['DESCR']了解每个属性的具体含义；
* 数据集划分：随机选出20%数据作为测试集，不做验证集要求；
* 性能度量：accuracy。

<!-- more -->

## 2. 线性回归

### 2.1 公式法

**我们先不考虑特征工程，仅将所有特征放入线性回归模型中**。

> 首先导入需要的第三方库

```python
from sklearn.datasets import load_boston #数据集
from sklearn import preprocessing #归一化处理
from sklearn.model_selection import train_test_split #数据集划分
import pandas as pd #观察数据集
import matplotlib.pyplot as plt #绘制图表
import numpy as np #数据处理
pd.set_option('precision', 2) #设置pandas显示数据保留两位小数
```

> 然后看看数据的大致范围与一些统计信息

```python
boston = load_boston() #加载数据，load_boston()返回的是一个字典
print(boston['DESCR']) #打印数据集描述信息

filepath = boston['filename'] #调用load_boston()会下载数据集csv文件到本地，通过filename获取路径
df = pd.read_csv(filepath, skiprows=0, header=1) #通过pandas读取csv文件，由于sklearn下载的csv文件第0行是样例数和属性数，第1行是属性名称，从第2行开始才是数据，所以设置skiprows跳过第0行，设置header特征行为1
df.describe() #显示数据集统计信息
```

{% asset_img boston.png linear %}

> 数据集划分

```python
data = boston['data'] #data对应前13列，即特征列，获取到的数据类型为np.array
target = boston['target'] #target对应最后一列，即目标列

x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, shuffle=True) #调用train_test_split划分数据集，指定test_size为0.2，指定shuffle为True，在划分前打乱数据集

# 注释掉的部分是对数据进行归一化处理，减去均值，再除以标准差
# scaler = preprocessing.StandardScaler().fit(x_train)
# x_train_scale = scaler.transform(x_train)
# x_test_scale = scaler.transform(x_test)
# x_train_scale = np.column_stack((x_train_scale, np.ones(len(x_train_scale))))
# x_test_scale = np.column_stack((x_test_scale, np.ones(len(x_test_scale))))

x_train = np.column_stack((x_train, np.ones(len(x_train)))) #在公式法中我们还要增加一列全1为偏差bias
x_test = np.column_stack((x_test, np.ones(len(x_test))))
```

> 计算预测值与损失

```python
def standLR(x, y):
    '''
        根据公式计算参数w（已经包括bias）
    '''
    xMat = np.mat(x) #将np.array数据转成矩阵便于后续计算
    yMat = np.mat(y).T #对应一列

    xTx = xMat.T * xMat #.T实现矩阵转置
    if np.linalg.det(xTx) == 0.0: #如果矩阵行列式为0说明矩阵不可逆
        print('矩阵不可逆，请使用其他方法！！')
        return
    w = xTx.I * xMat.T * yMat #计算w，w的形状是一列
    return w

def predict(x, w):
    return np.mat(x) * w #根据w计算预测值，预测值也是一列

def mse(pre, y):
    m = y.shape[0]
    yMat = np.mat(y).T
    loss = np.sum(np.square(pre - yMat)) / m #计算MSE，也可以开方获取RMSE
    return loss

w = standLR(x_train, y_train)
pre = predict(x_test, w)
loss = mse(pre, y_test)
print('MSE for testSet is: {:.3f}'.format(loss))

#绘制预测值与真实值，以y=x为标准，越接近这条线越准确
plt.figure(figsize=(4, 4))
plt.plot([0, 60], [0, 60])
plt.scatter(pre.A, y_test)
plt.show()
```

> MSE for testSet is: 26.741 ，每次结果都不一定相同

{% asset_img standpre.png linear %}

* 当使用了归一化后的特征列数据进行求解时，我们最后得到的预测性能和没有使用归一化的是几乎一样的，但是这是不是意味着归一化没有用处呢，当然不是；
* 在不考虑特征工程的情形下，我们仅通过线性回归能得到的完美解$w$，在测试集上的损失是23.541，我们要想提高性能减少损失需要考虑特征工程或其他方法；
* 当样例数和特征数增大时，矩阵计算需要大量内存，这个方法不合适；
* 在标准线性回归中，我们没有考虑单个样本损失的权重，比如测试点与某些样本点距离很近，那么这些近距离的样本点的损失对测试点就应当更重要，所以它们的损失权重应该较大，而那些远离测试点的样本点，其权重应当较小，基于这个理论，我们使用局部加权线性回归测试一下。

### 2.2 局部加权线性回归LWLR

```python
def lwlr(x_point, x, y, k=1.0):
    '''
        Description：
            局部加权线性回归，在待预测点附近的每个点赋予一定的权重，在子集上基于最小均方差来进行普通的回归。
        Notes:
            这其中会用到计算权重的公式，w = e^((x^((i))-x) / -2k^2)
            理解：x为某个预测点，x^((i))为样本点，样本点距离预测点越近，贡献的误差越大（权值越大），越远则贡献的误差越小（权值越小）。
            关于预测点的选取，在我的代码中取的是样本点。其中k是带宽参数，控制w（钟形函数）的宽窄程度，类似于高斯函数的标准差。
            算法思路：假设预测点取样本点中的第i个样本点（共m个样本点），遍历1到m个样本点（含第i个），算出每一个样本点与预测点的距离，
            也就可以计算出每个样本贡献误差的权值，可以看出w是一个有m个元素的向量（写成对角阵形式）。
    '''
    xMat = np.mat(x)
    yMat = np.mat(y).T
    x_point = np.mat(x_point)
    m = np.shape(xMat)[0]
    weights = np.mat(np.eye(m))     # eye()返回一个对角线元素为1，其他元素为0的二维数组，创建权重矩阵weights，该矩阵为每个样本点初始化了一个权重
    for j in range(m):
        diff = x_point - xMat[j, :]         # 计算 testPoint 与输入样本点之间的距离，然后下面计算出每个样本贡献误差的权值
        # print(diff * diff.T)
        weights[j, j] = np.exp(diff * diff.T / (-2.0 * k**2))
        # print(weights[j, j])
    xTx = xMat.T * (weights * xMat)     # 根据矩阵乘法计算 xTx ，其中的 weights 矩阵是样本点对应的权重矩阵
    if np.linalg.det(xTx) == 0.0: #如果矩阵行列式为0说明矩阵不可逆
        print('矩阵不可逆，请使用其他方法！！')
        return
    w = xTx.I * (xMat.T * (weights * yMat))
    return x_point * w

def lwlrPre(x_test, x, y, k=1.0):
    m = x_test.shape[0]
    pre = np.mat(np.zeros((m, 1)))
    for i in range(m):
        pre[i] = lwlr(x_test[i], x, y, k)
    return pre
# 这里使用了归一化后的数据，因为没有归一化的样本的diff值很大，导致exp运算后的值接近0，最后导致矩阵行列式为0
pre = lwlrPre(x_test_scale, x_train_scale, y_train, k=1.1)
loss = mse(pre, y_test)
print('MSE for testSet is: {:.3f}'.format(loss))

plt.figure(figsize=(4, 4))
plt.plot([0, 60], [0, 60])
plt.scatter(pre.A, y_test)
plt.show()
```
> MSE for testSet is: 7.435 ，每次结果都不一定相同，但是效果明显优于标准线性回归

{% asset_img lwlrpre.png linear %}

### 2.3 岭回归

```python
def ridgeRegress(x, y, lam=0.2):
    '''
        Desc：
            这个函数实现了给定 lambda 下的岭回归求解。
            如果数据的特征比样本点还多，就不能再使用上面介绍的的线性回归和局部现行回归了，因为计算 (xTx)^(-1)会出现错误。
            如果特征比样本点还多（n > m），也就是说，输入数据的矩阵x不是满秩矩阵。非满秩矩阵在求逆时会出现问题。
            为了解决这个问题，我们下边讲一下：岭回归，这是我们要讲的第一种缩减方法。
    '''
    xMat = np.mat(x)
    yMat = np.mat(y).T
    xTx = xMat.T * xMat
    demon = xTx + np.eye(xMat.shape[1]) * lam     # 岭回归就是在矩阵 xTx 上加一个 λI 从而使得矩阵非奇异，进而能对 xTx + λI 求逆
    if np.linalg.det(xTx) == 0.0: #如果矩阵行列式为0说明矩阵不可逆
        print('矩阵不可逆，请使用其他方法！！')
        return
    w = xTx.I * (xMat.T * yMat)
    return w
# 由于我们使用的数据集不存在特征比样本点还多的情况，因此岭回归未起作用
w = ridgeRegress(x_train_scale, y_train, lam=0.2)
pre = predict(x_test_scale, w)
loss = mse(pre, y_test)
print(loss)

plt.figure(figsize=(4, 4))
plt.plot([0, 60], [0, 60])
plt.scatter(pre.A, y_test)
plt.show()
```
> MSE for testSet is: 26.741 ，每次结果都不一定相同

{% asset_img standpre.png linear %}

### 2.4 Estimator

使用梯度下降可以避免公式法面临的内存消耗问题，同时采用归一化，归一化是为了保证在梯度下降时各个参数下降步长基本同步，达到同时收敛的效果

**基于Tensorflow框架实现线性回归，使用Tensorflow提供的LinearRegressor**

```python
#coding=utf-8

import tensorflow as tf
import numpy as np
from tensorflow.keras.datasets import boston_housing
from sklearn import preprocessing
# 默认划分20%的测试集
(x_train, y_train), (x_test, y_test) = boston_housing.load_data()

# 注释掉的部分对数据进行归一化处理，可以加速收敛
# scaler = preprocessing.StandardScaler().fit(x_train)
# x_train = scaler.transform(x_train)
# x_test = scaler.transform(x_test)

# 这里是为了适配LinearRegressor需要的feature_columns，而feature_columns指定了参与训练的特征，我们可以直接增加或减少feature_columns来比较在不同特征数下模型的性能
# 把每一列数据保存为一个键值对，键的名称来源数据集说明
column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',
                'TAX', 'PTRATIO', 'B', 'LSTAT']
def createDict(X):
    return { column_names[i]: X[:, i].ravel() for i in range(len(column_names))}

# 在这里控制参与训练的特征列
# 终极小tips，feature_columns的key不能包含空格在名称中，否则报错not valid scope name
feature_columns = []
for key in column_names:
    feature_columns.append(tf.feature_column.numeric_column(key=key))

# estimator的输入数据是一个dataset模式，具体可以上官网了解
def input_train():
    dataset = tf.data.Dataset.from_tensor_slices((createDict(x_train), y_train))
    dataset = dataset.shuffle(1000).batch(64).repeat() # 数据集打乱/batch/重复
    return dataset.make_one_shot_iterator().get_next()

def input_test():
    dataset = tf.data.Dataset.from_tensor_slices((createDict(x_test), y_test))
    dataset = dataset.shuffle(1000).batch(64)
    return dataset.make_one_shot_iterator().get_next()

# LinearRegressor的参数还可以指定优化器、参数正则化等等
model = tf.estimator.LinearRegressor(
    feature_columns=feature_columns, # 指定特征列
    model_dir="C://Users//Admin//Desktop//model", # 指定模型保存的位置，包括了checkpoint和tensorboard数据
    optimizer=tf.train.FtrlOptimizer(
      learning_rate=0.1,
      l1_regularization_strength=0.001
    ))

model.train(input_fn=input_train, steps=20000) # 开始训练模型，steps指定训练次数，每一次消耗一个batch的数据，进行一次参数更新

model.evaluate(input_fn=input_test) # 使用测试集数据评估模型性能，若使用的是同一组训练集和测试集，那么梯度下降最终得到的损失应该不低于直接用公式法得到的损失
```
**不使用归一化**：

> 'average_loss': 26.594913
> 'label/mean': 23.078432
> 'prediction/mean': 23.884363

**使用归一化**：

> 'average_loss': 23.19075
> 'label/mean': 23.078432
> 'prediction/mean': 23.093945

{% asset_img loss.png linear %}

## 3. 二分类sigmoid

### 3.1 简单梯度下降

```python
#coding=utf-8
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

rawData = load_breast_cancer()

data = rawData['data']
target = rawData['target']

x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, shuffle=True)

x_train = np.column_stack((x_train, np.ones(len(x_train))))
x_test = np.column_stack((x_test, np.ones(len(x_test))))

# sigmoid函数存在上溢和下溢问题
def sigmoid(x):
    return 1.0 / (1 + np.exp(-x))

def standGrad(x, y):
    xMat = np.mat(x)
    yMat = np.mat(y).T
    n = xMat.shape[1]
    alpha = 0.01
    steps = 1000
    weights = np.ones((n, 1))
    # 关键部分，根据迭代次数steps，每次迭代都使用全部数据，公式计算
    for i in range(steps):
        pre = sigmoid(xMat * weights)
        error = pre - yMat
        weights -= alpha * xMat.T * error
    return weights

# sigmoid函数计算得到预测值为1的概率，若概率大于0.5（也可以设置为其他值，
# 避免类别不均衡问题），则认为预测值为1
def predict(x, w):
    xMat = np.mat(x)
    pro = sigmoid(xMat * w) 
    pre = [1 if p > 0.5 else 0 for p in pro]
    return pro, pre

def accuracy(pre, y):
    return np.sum(np.equal(pre, y).astype(np.float))/len(pre)

w = standGrad(x_train, y_train)
pro, pre = predict(x_test, w)
print('Testset prediction accuracy: {:.3f}'.format(accuracy(pre, y_test)))
```
> Testset prediction accuracy: 0.763

### 3.2 随机梯度下降

```python
def stocGrad(x, y, steps=300):
    m, n = x.shape
    weights = np.ones(n)
    for i in range(steps):
        index = list(range(m))
        for j in range(m):
            rand_index = int(np.random.uniform(0, len(index)))
            alpha = 4 / (1.0 + i + j) + 0.01
            pre = sigmoid(np.sum(x[index[rand_index]] * weights))
            error = pre - y[index[rand_index]]
            weights -= alpha * error * x[index[rand_index]]
            del(index[rand_index])
    return np.mat(weights).T

w = stocGrad(x_train, y_train)
pro, pre = predict(x_test, w)
print('Testset prediction accuracy: {:.3f}'.format(accuracy(pre, y_test)))
```
> Testset prediction accuracy: 0.851

### 3.3 Estimator

**基于Tensorflow框架实现二分类，使用Tensorflow提供的LinearClassifier**

```python
#coding=utf-8

import tensorflow as tf
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn import preprocessing
from sklearn.model_selection import train_test_split

rawData = load_breast_cancer()

data = rawData['data']
target = rawData['target']

# 终极小tips，feature_columns的key不能包含空格在名称中，否则报错not valid scope name
column_names = [name.replace(' ', '') for name in rawData['feature_names']]

x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, shuffle=True)

def createDict(X):
    return {column_names[i]: X[:, i].ravel() for i in range(len(column_names))}

feature_columns = []
for key in column_names:
    feature_columns.append(tf.feature_column.numeric_column(key=key))

# 使用一个函数代替input_train和input_test
def input_fn(x, y, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((createDict(x), y))
    if training:
        dataset = dataset.shuffle(1000).batch(32).repeat()
    else:
        dataset = dataset.batch(32)
    return dataset.make_one_shot_iterator().get_next()

model = tf.estimator.LinearClassifier(
    n_classes=2, # 默认为2，可以不写，其他分类需要指定
    feature_columns=feature_columns, # 指定特征列
    model_dir="C://Users//Admin//Desktop//model//classifier", # 指定模型保存的位置，包括了checkpoint和tensorboard数据
    optimizer=tf.train.FtrlOptimizer(
      learning_rate=0.1,
      l1_regularization_strength=0.001 # 增加l1正则化，系数0.001，使参数中产生更多的0，可以提高泛化性能
    ))

model.train(input_fn=lambda: input_fn(x_train, y_train), steps=10000)

model.evaluate(input_fn=lambda: input_fn(x_test, y_test, training=False))
```

> 'accuracy': 0.95614034
> 'accuracy_baseline': 0.65789473
> 'auc': 0.9890598
> 'auc_precision_recall': 0.99319196
> 'average_loss': 0.10730305
> 'label/mean': 0.65789473
> 'loss': 3.058137
> 'precision': 0.972973
> 'prediction/mean': 0.6475287
> 'recall': 0.96
> 'global_step': 10000

## 4. 多分类softmax



## 5. LDA降维