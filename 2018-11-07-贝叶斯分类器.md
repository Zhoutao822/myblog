---
title: 贝叶斯分类器
date: 2018-11-07 17:40:33
categories:
- Machine Learning
tags:
- Theory
- Bayes
- Gibbs Sampling
mathjax: true
---

**贝叶斯无敌**

参考：

>西瓜书第7章 贝叶斯分类器

## 1. 贝叶斯决策论

贝叶斯决策论是概率框架下实施决策的基本方法。对于分类任务来说，在所有相关概率都已知的理想情形下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。

以多分类任务为例，假设有$N$种可能的类别标记，即$Y =\{ c_1, c_2,...,c_N \}$，$\lambda_{ij}$是将一个真实标记为$c_j$的样本误分类为$c_i$所产生的损失。那么在样本$\boldsymbol{x}$上的条件风险为

$$
R(c_i|\boldsymbol{x}) = \sum^N_{j=1}\lambda_{ij}P(c_j|\boldsymbol{x})
$$

我们的任务是寻找一个判定准则：$h:X \rightarrow Y$以最小化总体风险

$$
R(h) = \mathbb{E}_\boldsymbol{x}[R(h(\boldsymbol{x})|\boldsymbol{x})]
$$

<!-- more -->

显然，为了最小化总体风险，只需要在每个样本上选择那个能使条件风险$R(c|\boldsymbol{x})$最小的类别标记，即

$$
h^*(\boldsymbol{x}) = \underset{c \in Y}{\arg\min} R(c|\boldsymbol{x})
$$

举个例子

{% asset_img gmm02.png 混合高斯分布 %}

对于上图来说，假如我们已知点的分布属于两个高斯分布，对应两个类别，我们如何判断图中某点的类别呢？为了最小化总体风险，选择该点在两个高斯分布中概率最高的那个对应的种类。在这个过程中我们只计算了该点的两个高斯分布概率，这就是贝叶斯决策论的基本思想。

如果目标是最小化分类错误率，则$\lambda_{ij}$可写为

$$
\lambda_{ij} = \left\{\begin{matrix}
0, \quad if \quad i=j\\ 
1, \quad otherwise
\end{matrix}\right.
$$

此时条件风险

$$
R(c|\boldsymbol{x}) = 1-P(c|\boldsymbol{x})
$$

于是，最小化分类错误率的贝叶斯最优分类器为

$$
h^*(\boldsymbol{x}) = \underset{c\in Y}{\arg \max} P(c|\boldsymbol{x})
$$

即对每个样本选择能使后验概率$P(c|\boldsymbol{x})$最大的分类标记。

对应上面图中描述的，我们事先知道数据的分布才能很容易解决这个问题，但是实际上，数据分布通常难以直接获得，即$P(c|\boldsymbol{x})$后验概率难以直接获取。
从这个角度来看，机器学习所要实现的是基于有限的样本尽可能准确地估计出后验概率。
大体来说，主要有两种策略：

* 判别式模型：给定$\boldsymbol{x}$，可通过直接建模$P(c|\boldsymbol{x})$来预测$c$，决策树、BP神经网络、SVM等；
* 生成式模型：先对联合概率分布$P(\boldsymbol{x}, c)$建模，然后再由此获得$P(c|\boldsymbol{x})$。

对生成式模型来说，基于贝叶斯定理

$$
P(c|\boldsymbol{x}) = \frac{P(c)P(\boldsymbol{x}|c)}{P(\boldsymbol{x})}
$$

其中$P(c)$是类先验概率；$P(\boldsymbol{x}|c)$是样本相对于类标记$c$的类条件概率，或称为似然；$P(\boldsymbol{x})$是用于归一化的证据因子（与类别标记无关，一般无需计算）。

类先验概率$P(c)$表达了样本空间各类样本所占的比例，根据大数定律，可以通过各类样本出现的频率来进行估计。

对类条件概率$P(\boldsymbol{x}|c)$来说，它涉及到关于$\boldsymbol{x}$所有属性的联合概率，直接根据样本出现的频率来估计会很困难。例如，假设样本的$d$个属性都是二值的，则样本空间将有$2^d$种可能取值，在现实应用中，这个值往往大于训练样本数$m$，也就是说，很多样本取值没有在训练集种出现，不可直接用频率估计$P(\boldsymbol{x}|c)$。

## 2. 极大似然估计

估计类条件概率的一般策略是

1. 假设样本属于某个类别；
2. 基于假设的类别对概率分布的参数进行估计；
3. 根据更新后的参数重新计算样本的类别

重复2和3直到收敛。

事实上，概率模型的训练过程就是参数估计过程。

令$D_c$表示训练集中第$c$类样本组成的集合，假设这些样本是独立同分布的，则参数$\boldsymbol{\theta}_c$对于数据集$D_c$的似然是

$$
P(D_c|\boldsymbol{\theta}_c) = \prod_{\boldsymbol{x}\in D_c}P(\boldsymbol{x}|\boldsymbol{\theta}_c)
$$

对$\boldsymbol{\theta}_c$进行极大似然估计，就是去寻找能最大化似然$P(D_c|\boldsymbol{\theta}_c)$的参数$\boldsymbol{\theta}_c$，即在参数所有可能取值中找到能使数据出现可能性最大的参数。

连乘容易造成下溢，通常使用对数似然

$$
LL(\boldsymbol{\theta}_c) = \log P(D_c|\boldsymbol{\theta}_c)
\\
=\sum_{\boldsymbol{x}\in D_c}\log P(\boldsymbol{x}|\boldsymbol{\theta}_c)
$$

显然极大似然估计为

$$
\hat{\boldsymbol{\theta}}_c = \underset{\boldsymbol{\theta}_c}{\arg\max} LL(\boldsymbol{\theta}_c)
$$

例如，上图中的高斯分布，假设概率密度函数$p(\boldsymbol{x}|c)\sim N(\boldsymbol{\mu}_c,\boldsymbol{\sigma}^2_c)$，则参数的极大似然估计为

$$
\hat{\boldsymbol{\mu}}_c = \frac{1}{|D_c|}\sum_{\boldsymbol{x}\in D_c}\boldsymbol{x}
\\
\hat{\boldsymbol{\sigma}}^2_c =\frac{1}{|D_c|}\sum_{\boldsymbol{x}\in D_c}(\boldsymbol{x} - \hat{\boldsymbol{\mu}}_c)(\boldsymbol{x} - \hat{\boldsymbol{\mu}}_c)^T
$$

我们能做出如此假设的前提是，在可视化的条件下我们发现数据很大程度是属于两个高斯分布的。然而事实上，我们无法知道数据的分布，可能数据的维度很高，可能数据量很大，如果“假设”出错，那么我们的结果可能会是失败的。

## 3. 朴素贝叶斯分类器

朴素贝叶斯分类是为了解决类条件概率$P(\boldsymbol{x}|c)$无法直接获取的问题，采用了属性条件独立性假设：对已知类别，假设所有属性相互独立，即假设每个属性独立地对分类结果发生影响。

基于上述假设

$$
P(c|\boldsymbol{x}) = \frac{P(c)P(\boldsymbol{x}|c)}{P(\boldsymbol{x})} = \frac{P(c)}{P(\boldsymbol{x})} \prod^d_{i=1}P(x_i|c)
$$

$d$为属性数目，$x_i$为样本在第$i$个属性上的取值。

对于所有类别来说，基于上式的贝叶斯判定准则为

$$
h_{nb}(\boldsymbol{x}) = \underset{c\in Y}{\arg\max}P(c)\prod^d_{i=1}P(x_i|c)
$$

这就是朴素贝叶斯分类器的表达式。

令$D_c$表示训练集$D中第$c$类样本组成的集合，若有充足的独立同分布样本，则

$$
P(c) = \frac{|D_c|}{|D|}
$$

对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则

$$
P(x_i|c) = \frac{|D_{c, x_i}|}{|D_c|}
$$

显然，连乘过程中如果出现了0，那么整个概率都变成了0，我们需要进行修正，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数

$$
\hat{P}(c) = \frac{|D_c|+1}{|D|+N}
\\
\hat{P}(x_i|c) = \frac{|D_{c, x_i}|+1}{|D_c|+N}
$$

## 4. 半朴素贝叶斯分类器

朴素贝叶斯分类器基于属性条件独立性假设，但是现实任务中这个假设往往很难成立。考虑一部分属性间的相互依赖信息，这就是半朴素贝叶斯分类器的基本思想。独依赖估计ODE是半朴素贝叶斯分类器最常用的一种策略，即假设每个属性在类别之外最多仅依赖于一个其他属性

$$
P(c|\boldsymbol{x}) \propto P(c)\prod^d_{i=1}P(x_i|c, pa_i)
$$

其中$pa_i$为属性$x_i$所依赖的属性，称为父属性。如何确定父属性？

---

最直接的做法是假设所有属性都依赖于同一个属性，称为超父，通过交叉验证等模型选择方法确定超父属性，由此形成了SPODE方法。

{% asset_img spode.jpg %}

---

TAN则是在最大带权生成树算法的基础上，通过以下步骤将属性间依赖关系约简

1. 计算任意两个属性之间的条件互信息$I(x_i,x_j|y) = \sum_{x_i,x_j|y}\log \frac{P(x_i,x_j|c)}{P(x_i|c)P(x_j|c)}$
2. 以属性为结点构建完全图，任意两个结点之间边的权重设为$I(x_i, x_j|y)$；
3. 构建此完全图的最大带权生成树，挑选根变量，将边置为有向；
4. 加入类别结点$y$，增加从$y$到每个属性的有向边。

通过最大生成树算法，TAN实际上仅保留了强相关属性之间的依赖性。

---

AODE是一种基于集成学习机制、更为强大的独依赖分类器。AODE尝试将每个属性作为超父来构建SPODE，然后将那些具有足够数据支撑的SPODE集成起来作为最终结果

$$
P(c|\boldsymbol{x}) \propto \underset{|D_{x_i}|\geqslant m'}{\sum^d_{i=1}} P(c, x_i)\prod^d_{j=1}P(x_j|c, x_j)
$$

其中$D_{x_i}$是在第$i$个属性上取值为$x_i$的样本的集合，$m'$为阈值常数。

$$
\hat{P}(c,x_i) = \frac{|D_{c, x_i}|+1}{|D|+N\times N_i}
\\
\hat{P}(x_j|c, x_i) = \frac{|D_{c, x_i, x_j}|+1}{|D_{c,x_i}|+N_j}
$$

$D_{c,x_i}$是类别为$c$且在第$i$个属性上取值为$x_i$的样本集合，$D_{c, x_i,x_j}$是类别为$c$且在第$i$和$j$个属性上取值分别为$x_i$和$x_j$的样本集合。

---

同样的，假设父属性为$k$个，即高阶依赖，那么所需要的训练样本数将以指数级增加。

## 5. 贝叶斯网

贝叶斯网亦称为信念网，它借助有向无环图DAG来刻画属性之间的依赖关系，并使用条件概率表CPT来描述属性的联合概率分布。

一个贝叶斯网$B$由结构$G$和参数$\Theta$两部分构成，即$B=\left \langle G, \Theta \right \rangle$。网络结构$G$是一个有向无环图，其每个结点对应于一个属性，若两个属性之间有直接依赖关系，则它们由一条边连接起来；参数$\Theta$定量描述这种依赖关系，假设属性$x_i$在$G$中的父结点集为$\pi_i$，则$\Theta$包含了每个属性的条件概率表$\theta_{x_i|\pi_i} = P_B(x_i|\pi_i)$。

{% asset_img bayes0.jpg 西瓜问题 %}

在上图中，我们可以知道$P(根蒂 = 硬挺|甜度 = 高) = 0.1$

### 5.1 结构

给定父结点集，贝叶斯网假设每个属性与它的非后裔属性独立，于是属性的联合概率分布为

$$
P_B(x_i,x_2,...,x_d) = \prod^d_{i=1}P_B(x_i|\pi_i) = \prod^d_{i=1} \theta_{x_i|\pi_i}
$$

以上图为例，联合概率分布为

$$
P(x_1, x_2, x_3,x_4,x_5) = P(x_1)P(x_2)P(x_3|x_1)P(x_4|x_1,x_2)P(x_5|x_2)
$$

相互独立关系表示为 $x_3 \perp x_4|x_1$和$x_4 \perp x_5|x_2$。

贝叶斯网中三个变量之间的典型依赖关系为

{% asset_img bayes1.png 贝叶斯网中三个变量之间的典型依赖关系 %}

在同父结构中，给定父结点$x_1$的取值，则$x_3$和$x_4$条件独立；在顺序结构中，给定$x$的值，则$y$与$z$条件独立；V型结构，给定子结点$x_4$的值，$x_1$和$x_2$必不独立，若$x_4$取值完全未知，则V型结构下$x_1$和$x_2$却是相互独立的。

事实上，一个变量取值的确定与否，能对另两个变量间的独立性发生影响。为了分析有向图中变量间的条件独立性，可使用有向分离。我们先把有向图转变为一个无向图：

* 找出有向图中所有的V型结构，在V型结构的两个父结点之间加上一条无向边；
* 将所有有向边改为无向边。

由此产生的无向图称为道德图，令父结点相连的过程称为道德化。基于道德图能直观地、迅速地找到变量间的条件独立性。从道德图中将变量集合$\boldsymbol{z}$去除后，$x$和$y$分属两个连通分支，则称变量$x$和$y$被$\boldsymbol{z}$有向分离，$x \perp y|\boldsymbol{z}$。

{% asset_img bayes2.png 道德图 %}

### 5.2 学习

若网络结构已知，则贝叶斯网的学习过程只需通过对训练样本计数，估计出每个结点的条件概率表即可。但在现实应用中我们往往并不知晓网络结构，于是，首要任务变成根据数据集找出结构最恰当的贝叶斯网。
评分搜索是求解这一问题的常用方法，通过一个评分函数评估贝叶斯网与训练数据的契合程度，基于评分函数来寻找结构最优的贝叶斯网。

常用评分函数通常基于信息论准则，学习的目标是找到一个能以最短编码长度描述训练数据的模型，此时编码的长度包括了描述模型自身所需的字节长度和使用该模型描述数据所需的字节长度。
对贝叶斯网来说，模型就是一个贝叶斯网，根据条件概率表，我们的目标是用一套编码机制使那些经常出现的样本具有更短的编码。于是我们应选择那个综合编码长度最短的贝叶斯网，这就是最小描述长度MDL准则。

给定训练集$D = \{ \boldsymbol{x}_1,\boldsymbol{x}_2,...,\boldsymbol{x}_m \}$，贝叶斯网$B=\left \langle G, \Theta \right \rangle$在$D$上的评分函数可写为

$$
s(B|D) = f(\theta)|B| - LL(B|D)
$$

其中$|B|$是贝叶斯网的参数个数，$f(\theta)$表示描述每个参数$\theta$所需的字节数，而

$$
LL(B|D) = \sum^m_{i=1}\log P_B(\boldsymbol{x}_i)
$$

是贝叶斯网的对数似然。我们的任务变成了寻找一个贝叶斯网是评分函数$s$最小。

若$f(\theta) = 1$，即每个参数用1字节描述，则得到AIC评分函数

$$
AIC(B|D) = |B| - LL(B|D)
$$

若$f(\theta) = \frac{1}{2}\log m$，即每个参数用$\frac{1}{2}\log m$字节描述，则得到BIC评分函数

$$
BIC(B|D) = \frac{\log m}{2}|B| - LL(B|D)
$$

显然，若$f(\theta) = 0$，即不考虑对网络进行编码，则评分函数退化为负对数似然，相应的学习任务退化为极大似然估计。

若贝叶斯网$B$结构固定，则评分函数第一项为常数。此时，最小化$s$等价于对$\Theta$的极大似然估计。极大似然估计需要的参数$\theta_{x_i|\pi_i}$能直接在训练数据$D$上通过经验估计获得

$$
\theta_{x_i|\pi_i} = \hat{P}_D(x_i|\pi_i)
$$

其中$\hat{P}_D(\cdot)$是$D$上的经验分布。因此，为了最小化$s$，只需要对网络结构进行搜索，候选结构的参数可以直接根据训练集直接计算。

然而，从所有可能的网络结构空间中搜索最优贝叶斯网结构是NP难问题。
常用的两种策略能在有限时间内求得近似解：

1. 贪心法，从某个网络结构出发，每次调整一条边，直到评分函数值不再降低为止；
2. 通过给网络结构施加约束来削减搜索空间，例如将网络结构限定为树形结构等。

### 5.3 推断

贝叶斯网训练好之后就能用来查询，即通过一些属性变量的观测值来推测其他属性变量的取值。

最理想的是直接根据贝叶斯网定义的联合概率分布来精确计算后验概率，然而这是NP难问题；换言之，需要借助近似推断，通过降低精度要求，在有限时间内求得近似解。在现实应用中，贝叶斯网的近似推断常使用吉布斯采样来完成。

{% asset_img bayes3.png 吉布斯采样算法 %}

令$\boldsymbol{Q} = \{ Q_1,Q_2,...,Q_n \}$表示待查询变量，$\boldsymbol{E} = \{ E_1,E_2,...,E_k \}$为证据变量（观测属性），已知其取值为$\boldsymbol{e} = \{ e_1,e_2,...,e_k \}$。目标是计算后验概率$P(\boldsymbol{Q} = \boldsymbol{q}|\boldsymbol{E} = \boldsymbol{e})$，其中$\boldsymbol{q} = \{ q_1,q_2,...,q_n \}$是带查询变量的一组取值。以西瓜问题为例，待查询变量为$\boldsymbol{Q} = \{ 好瓜，甜度 \}$，证据变量为$\boldsymbol{E} = \{ 色泽，敲声，根蒂 \}$，且其取值为$\boldsymbol{e} = \{ 青绿，浊响，蜷缩 \}$，查询的目标值是$\boldsymbol{q} = \{ 是，高 \}$，即这是好瓜且甜度高的概率有多大。

吉布斯采样算法：

1. 首先随机产生一个与证据样本$\boldsymbol{E} = \boldsymbol{e}$一致的样本$\boldsymbol{q}^0$作为初始点；
2. 重复当前步骤，从当前样本出发产生下一个样本：在第$t$次采样中，先假设$\boldsymbol{q}^t = \boldsymbol{q}^{t-1}$，然后对非证据变量逐个进行采样改变其取值，采样概率根据贝叶斯网$B$和其他变量的当前取值（$\boldsymbol{Z} = \boldsymbol{z}$）计算获得。
3. 经过$T$次采样得到的与$\boldsymbol{q}$一致的样本共有$n_q$个，则近似估算出后验概率为：$P(\boldsymbol{Q} = \boldsymbol{q}|\boldsymbol{E} = \boldsymbol{e}) \simeq \frac{n_q}{T}$

实质上，这是一个马尔可夫链，在一定条件下，无论从什么初始状态开始，必收敛于一个平稳分布；对于吉布斯采样来说，这个分布恰好是$P(\boldsymbol{Q}|\boldsymbol{E} = \boldsymbol{e})$。因此，当$T$很大时，采样收敛于$P(\boldsymbol{Q} = \boldsymbol{q}|\boldsymbol{E} = \boldsymbol{e})$。若贝叶斯网中存在极端概率0或1，则不能保证马尔可夫链存在平稳分布，此时吉布斯采样会给出错误的估计。

## 6. EM算法

在前面的讨论中，我们一直假设训练样本所有属性变量的值都已被观测到，但是在现实应用中往往会遇到不完整的训练样本，例如西瓜的根蒂已经脱落，无法判断其属性值。在这种情况下，我们使用EM算法（期望最大化算法）对模型进行参数估计。

参考[`EM算法及其在学习HMM参数中的应用`](http://zhoutao822.coding.me/2018/11/16/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB-HMM/)


