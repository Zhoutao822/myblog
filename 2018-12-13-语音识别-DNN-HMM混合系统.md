---
title: 语音识别-DNN-HMM混合系统
date: 2018-12-13 16:20:38
categories:
- Speech Recognition
tags:
- Theory
- DNN-HMM
mathjax: true
---

参考：

> 《解析深度学习-语音识别实践》第6章 深度神经网络-隐马尔可夫模型混合系统

**语音识别过程：切除首尾端静音->声音划分为帧->对每一帧提取MFCC特征->若干帧对应一个状态->三个状态组成一个音素->若干音素组成单词**

## 1. DNN-HMM混合系统

在前面的`语音识别-GMM`和`语音识别-HMM`中我们已经知道了，对于音频数据，经过提取特征处理后，通过GMM得到状态，然后通过HMM描述语音信号的动态变化，以预测输出。得益于DNN强大的表现学习能力，使用DNN替代GMM用于估计观察特征的概率，这样的语音识别系统性能远优于传统的GMM-HMM系统。

<!-- more -->

### 1.1 结构

{% asset_img 0.png %}

HMM对语音信号的序列特性进行建模，DNN对所有聚类后的状态（聚类后的三音素状态）的**似然度**进行建模。

在给定声学观察特征的条件下，我们用DNN的每个输出节点来估计连续密度HMM的某个状态的后验概率（类似于DNN的softmax输出，包括所有状态的概率，取最大值对应的状态）。DNN-HMM有两个额外的好处：训练过程可以使用维特比算法，解码通常也非常高效。

对上下文相关因素的后验概率建模为

$$
p(s_i,c_j|\boldsymbol{x}_t) = p(s_i|\boldsymbol{x}_t)p(c_j|s_i,\boldsymbol{x}_t)
$$

或者

$$
p(s_i,c_j|\boldsymbol{x}_t) = p(c_j|\boldsymbol{x}_t)p(s_i|c_j,\boldsymbol{x}_t)
$$

其中$\boldsymbol{x}_t$是在$t$时刻的声学观察值，$c_j$是聚类后的上下文种类$\{ c_1, ..., c_J \}$中的一种，$s_i$是一个上下文无关的音素或音素中的状态。

为了提升性能：

1. 把传统的浅层神经网络替换成深层神经网络（可选择的预训练）；
2. 使用聚类后的状态（绑定后的三音素状态）替代单音素状态作为神经网络的输出单元。

这种改善后的模型称为CD-DNN-HMM，对于所有的状态$s \in [1, S]$，我们只训练一个完整的DNN来估计状态的后验概率$p(q_t = s|\boldsymbol{x}_t)$。这和传统的GMM是不同的，因为GMM框架下，我们会使用其多个不同的GMM对不同的状态建模。除此之外，典型的DNN输入不是单一的一帧，而是一个$2w+1$（如9 ~ 13）帧大小的窗口特征$\boldsymbol{x}_t = [\boldsymbol{o}_{\max (0, t-w)}...\boldsymbol{o}_t...\boldsymbol{o}_{\min (T, t+w)}]$，这使得相邻帧的信息可以被有效地利用。

### 1.2 用CD-DNN-HMM解码

解码过程中HMM需要似然度$p(\boldsymbol{x}_t|q_t)$，而不是后验概率：

$$
p(\boldsymbol{x}_t|q_t = s) = \frac{p(q_t = s|\boldsymbol{x}_t)p(\boldsymbol{x}_t)}{p(s)}
$$

其中$p(s) = \frac{T_s}{T}$是从训练集中统计地每个状态（聚类后地状态）的先验概率，$T_s$是标记属于状态$s$的帧数，$T$是总帧数。$p(\boldsymbol{x}_t)$是与字词序无关的，计算时可以忽略，得到近似缩放过的似然度$\bar{p}(\boldsymbol{x}_t|q_t) = \frac{p(q_t=s|\boldsymbol{x}_t)}{p(s)}$。

在CD-DNN-HMM解码出的字词序列$\hat{w}$由以下公式确定

$$
\hat{w} = \underset{w}{\arg \max} p(w|\boldsymbol{x}) = \underset{w}{\arg \max} \frac{p(\boldsymbol{x}|w)p(w)}{p(\boldsymbol{x})}
\\
= \underset{w}{\arg \max} p(\boldsymbol{x}|w)p(w)
$$

其中$p(w)$是语言模型（LM）概率，以及

$$
p(\boldsymbol{x}|w) = \sum_qp(\boldsymbol{x},q|w)p(q|w)
\\
\approx \pi(q_0) \prod^T_{t=1}a_{q_{t-1}q_t} \prod^T_{t=0}\frac{p(q_t|\boldsymbol{x}_t)}{p(q_t)}
$$

是声学模型（AM）的概率，其中$p(q_t|\boldsymbol{x}_t)$由DNN计算得出，$p(q_t)$是状态先验概率，这个概率也是训练过程中训练出来的（就是把观测值（特征向量）网状态上对齐，跟某个状态对齐的观测值的个数占比就是这个状态的先验概率），$\pi(q_0)$和$a_{q_{t-1}q_t}$分别是状态初始概率和状态转移概率，各自由HMM决定。语音模型权重稀疏$\lambda$用于平衡声学和语言模型得分，最终解码路径由以下公式确定

$$
\hat{w} = \underset{w}{\arg \max} [\log p(\boldsymbol{x}|w) + \lambda \log p(w)]
$$

### 1.3 CD-DNN-HMM训练过程

CD-DNN-HMM包含三个组成部分，一个深度神经网络dnn，一个隐马尔可夫模型hmm以及一个状态先验概率分布prior。

1. 首先训练一个状态共享的三音素 GMM-HMM 系统,使用决策树来决定如何共享状态。设训练完成的系统为 gmm-hmm。
2. 用步骤 1 得到的 gmm-hmm 初始化一个新隐马尔可夫模型(包括转移概率,观测概率,隐马尔可夫模型的状态),并生成一个 DNN-HMM 模型,设该模型为 dnn-hmm1。
3. 预训练 dnn-hmm1 系统中的深度神经网络,得到的深度神经网络为ptdnn。
4. 使用 gmm-hmm 系统对语音训练数据作排列(即求出训练数据对应哪个隐马尔可夫模型中的状态),得到的数据设为 align-raw。
5. 使用步骤 4 得到的数据对 ptdnn的参数作微调(可以使用随机梯度下降算法)。设得到的深度神经网络为 dnn。
6. 利用 dnn 与 dnn-hmm1 和最大似然算法重新估计隐马尔可夫中的参数(转移概率,观测概率),设新得到的系统为 dnn-hmm2。
7. 如果步骤 6 的精度不再提高则退出算法,否则使用 dnn 和 dnn-hmm2产生新的语音训练数据的排列数据,然后回到步骤 5。
8. 利用训练数据估计概率$p(q_t)$的值

### 1.4 上下文窗口的影响

使用一个窗（典型的是9到13）包含的全部帧特征作为CD-DNN-HMM的输入可以实现优异的性能。





