---
title: 集成学习
date: 2019-01-03 21:27:02
categories:
- Machine Learning
tags:
- Theory
- Ensemble Learning
mathjax: true
---

**三个臭皮匠，顶个诸葛亮？**

参考：

> 西瓜书第8章 集成学习

## 1. 个体与集成

集成学习，顾名思义就是多个学习器联合起来完成学习任务，那么问题来了，单个学习器是怎样形成的？这些学习器怎样联合起来？

{% asset_img 1.jpg %}

如图所示，个体学习器通常由一个现有的学习算法从训练数据中产生，例如C4.5决策树、BP神经网络等，那么有一些定义产生了（虽然没什么用）。

比如，若集成中只包含同种类型的个体学习器，则这样的集成是"同质"的（比如全是决策树或者全是神经网络）。同质集成中的个体学习器称为**基学习器**，相应的算法称为**基学习算法**。

当然集成中也可以包含不同类型的个体学习器，同理叫做"异质"的。异质集成中没有基学习器和基学习算法的概念。

集成学习通过将多个学习器进行结合，常可以获得比单一学习器显著优越的泛化性能（传说中的`三个臭皮匠，顶个诸葛亮`）。而且许多集成学习研究是针对于**弱学习器**（泛化性能略优于随机猜测的学习器，比如二分类准确度略高于50%），我觉得这是因为在现实任务中获得单一的极强泛化性能的学习器是非常困难（这里应该包括训练过程和数据获取难度），但是获得一个性能不那么强的学习器往往需要的成本会小很多，然后我们再根据数据类型，训练出多个类似的弱学习器，通过集成策略（比如投票）作为最终模型，那么成本降下来了，而且性能也还可以，所以这个能称为研究的方向。当然了，在实际问题中能够轻易得到强学习器，还是会使用强学习器作为个体学习器的，毕竟`强强联手`。

对于每个个体学习器而言，它必须满足一定的基础条件，否则它就会拖后腿（比如三个臭皮匠中有个混子，那就很难受了），所以第一个是**准确性**，即学习器不能太坏（二分类低于50%那就是个混子还会拖后腿），另一个是**多样性**，即学习器间具有差异（简单来说就是各个学习器考虑问题的方向不同，如果相同了，那不就是抄袭吗），综合起来四个字**好而不同**。

<!-- more -->

---

*集成学习性能证明*

考虑二分类问题$y \in \{ -1, +1 \}$和真实函数$f$，假定基分类器的错误率为$\epsilon$，即对每个基分类器$h_i$有

$$
P(h_i(\boldsymbol{x}) \neq f(\boldsymbol{x})) = \epsilon
$$

假设集成策略为简单投票法结合$T$个基分类器，超过半数原则

$$
H(\boldsymbol{x}) = sign(\sum^T_{i=1}h_i(\boldsymbol{x}))
$$

假设基分类器的错误率相互独立，则集成的错误率为

$$
P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) = \sum^{\left \lfloor T/2 \right \rfloor}_{k=0}\binom{T}{k}(1-\epsilon)^k\epsilon^{T-k}
\\
\leqslant \exp(-\frac{1}{2}T(1-2\epsilon)^2)
$$

上式表明，随着$T$增大，集成的错误率指数级下降，最终趋向于0。

注意，这个式子的前提是基学习器的错误率相互独立，也就是说每个基学习器考虑问题的方向不能有任何交叉（比如决策树之间的判定条件必须不同，选择的最优特征不同），显然很不现实，所以如何产生并结合好而不同的个体学习器，恰是集成学习研究的核心。

根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类：

1. 个体学习器间存在强依赖关系、必须串行生成的序列化方法，代表`Boosting`；
2. 个体学习器间不存在强依赖关系、可同时生成的并行化方法，代表`Bagging`和`随机森林`。

## 2. Boosting

Boosting算法工作机制：

1. 根据初始训练集训练出一个基学习器
2. 根据基学习器的表现对训练样本分布进行调整，使得先前基学习器错判的样本在后续受到更多关注
3. 基于调整后的样本分布来训练下一个基学习器
4. 判断基学习器数目是否达到指定的值$T$，未达到则返回第2步，否则将这$T$个基学习器进行加权结合

Boosting族算法中最著名的是AdaBoost，其中$y_i \in \{ -1, +1 \}$，$f$是真实函数。

{% asset_img 2.png %}

AdaBoost算法有多种推导方式，比较容易理解的是基于“加性模型”

$$
H(\boldsymbol{x}) = \sum^T_{t=1}\alpha_th_t(\boldsymbol{x})
$$

来最小化指数损失函数

$$
l_{\exp}(H|\boldsymbol{D}) = \mathbb{E}_{\boldsymbol{x} \sim \boldsymbol{D}}[e^{-f(\boldsymbol{x})H(\boldsymbol{x})}]
$$

对于二分类$y_i \in \{ -1, +1 \}$来说，损失函数可以有`0-1损失`、`Logistic loss`、`Hinge loss`、`指数损失(Exponential loss)`、`modified Huber loss`，这里选择指数损失的原因推导如下：

若$H(\boldsymbol{x})$能令指数损失最小化，则考虑上式对$H(\boldsymbol{x})$的偏导数

$$
\frac{\partial l_{\exp}(H|\boldsymbol{D})}{\partial H(\boldsymbol{x})} = -e^{-H(\boldsymbol{x})} P(f(\boldsymbol{x}) = 1|\boldsymbol{x}) + e^{H(\boldsymbol{x})} P(f(\boldsymbol{x}) = -1|\boldsymbol{x})
$$

令上式为0，解得

$$
H(\boldsymbol{x}) = \frac{1}{2}\ln\frac{P(f(\boldsymbol{x}) = 1|\boldsymbol{x})}{P(f(\boldsymbol{x}) = -1|\boldsymbol{x})}
$$

因此有

$$
sign(H(\boldsymbol{x})) = sign(\frac{1}{2}\ln\frac{P(f(\boldsymbol{x}) = 1|\boldsymbol{x})}{P(f(\boldsymbol{x}) = -1|\boldsymbol{x})})
\\
= \left\{\begin{matrix}
1, \quad P(f(\boldsymbol{x}) = 1|\boldsymbol{x}) > P(f(\boldsymbol{x}) = -1|\boldsymbol{x})\\ 
-1, \quad P(f(\boldsymbol{x}) = 1|\boldsymbol{x}) < P(f(\boldsymbol{x}) = -1|\boldsymbol{x})
\end{matrix}\right.
\\
= \underset{y\in \{ -1, 1 \}}{\arg \max} P(f(\boldsymbol{x}) = y|\boldsymbol{x})
$$

也就是说$sign(H(\boldsymbol{x}))$达到了贝叶斯最优错误率。换言之，指数损失函数最小化等价于分类错误率最小化；也就是说，`指数损失`函数是分类任务原本`0-1损失`函数的一致替代损失函数。而且指数损失函数有更好的数学性质，因此用它作为优化目标。

* 样本分布$\boldsymbol{D}_t$即各个样本的权值（这里相当于各个样本出现的概率），那么所有样本的权值的和必定为1；
* 基于分布$\boldsymbol{D}_t$从数据集$D$中训练出分类器$h_t$，即按照决策树的方式生成，比如信息增益，需要的参数如样本概率就对应样本权值分布；
* 如果误差大于0.5，那么放弃这个分类器，因为明显拖后腿，此时重新训练分类器的的准则应当更改（比如决策树选择的最佳分类特征，或分类特征的阈值）；
* 分类器权重$\alpha_t = \frac{1}{2}\ln(\frac{1-\epsilon_t}{\epsilon_t}) > 0$，显然，错误率越小，分类器权重越大，权重计算方式证明如下；
* 针对某个样本来说，若当前分类器能正确分类此样本，那么此样本的权重减小（乘以$\exp(-\alpha_t)$），若当前分类器不能正确分类此样本，那么此样本的权重增加（乘以$\exp(\alpha_t)$）。

---

分类器权重$\alpha_t$公式证明

当基分类器$h_t$基于分布$\boldsymbol{D}_t$产生后，该基分类器的权重$\alpha_t$应使得$\alpha_th_t$最小化指数损失函数

$$
l_{\exp}(\alpha_th_t|\boldsymbol{D}_t) = \mathbb{E}_{\boldsymbol{x} \sim \boldsymbol{D}_t}[e^{-f(\boldsymbol{x})\alpha_th_t(\boldsymbol{x})}]
\\

$$






## 3. Bagging与随机森林






## 4. 结合策略






## 5. 多样性









































