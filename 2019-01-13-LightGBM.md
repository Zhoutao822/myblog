---
title: LightGBM
date: 2019-01-13 21:39:40
categories:
- Machine Learning
tags:
- Theory
- LightGBM
mathjax: true
---

参考：

> [LightGBM: A Highly Efficient Gradient Boosting Decision Tree](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf)
> [LightGBM整理](https://dataxujing.github.io/LightGBM-learn/#1)
> [从结构到性能，一文概述XGBoost、Light GBM和CatBoost的同与不同](https://juejin.im/post/5ab1d713f265da238f126b87)
> [LightGBM核心解析与调参](https://juejin.im/post/5b76437ae51d45666b5d9b05)
> [LightGBM视频教程](https://v.qq.com/x/page/k0362z6lqix.html)
> [LightGBM 中文文档](http://lightgbm.apachecn.org/#/)

LightGBM属于Boosting一族，由微软开源，被评价为“速度惊人”，“非常有启发”，“支持分布式”，“内存占用小”等。

<!-- more -->

## 1. 回顾

### 1.1 Boosting

参考`决策树`

{% asset_img 0.png %}

### 1.2 Gradient Boosting

参考`GBDT`

## 2. Leaf-wise

{% asset_img 1.png %}

### 2.1 Level-wise算法

传统决策树算法采用的就是Level-wise算法，每次划分（连续值）都在减少当前结点的损失，在不考虑预剪枝的情况下，这种做法缺点是贪心，优点是可以利用多线程。

### 2.2 Leaf-wise算法

Leaf-wise算法主要用于LightGBM，它的核心思想是：在将结点一分为二后，考虑在损失最大的那个子结点上继续进行划分（这里比较的是全部数据集的损失，也就是说如果某次迭代中子树的损失小于其某个祖先的兄弟时，可以从祖先的兄弟继续划分子树）。这样可以很容易实现整体的最小损失，但是容易过拟合，我们可以通过控制树的深度避免过拟合。

上图中的$p,f,v$应该代表划分的样本子集，最佳特征，最佳特征对应的最佳阈值。

## 3. 对比XGBoost

参考`XGBoost`，首先了解一下XGBoost的优缺点

* 精确贪心算法
    * 优点：
        * 可以找到精确的划分条件
    * 缺点：
        * 计算量巨大
        * 内存占用巨大
        * 易产生过拟合
* Level-wise迭代方式
    * 优点：
        * 可以使用多线程
        * 可以加速精确贪心算法
    * 缺点： 
        * 效率低下，可能产生不必要的叶结点

LightGBM官方宣称的优点，很明显是针对XGBoost：

* 快速高效
* 内存占用低
* 准确率高
* 支持分布式
* 支持large-scale data
* 支持直接使用category特征

{% asset_img 2.png %}

表格中提到的Histogram algorithm稍后介绍，XGBoost与LightGBM的对比，看表格应该是LightGBM全面碾压XGBoost

{% asset_img 3.png %}

## 4. Histogram algorithm

{% asset_img 4.png %}

Histogram algorithm应该翻译为直方图算法，直方图算法的思想也很简单，首先将连续的浮点数据转换为bin数据，具体过程是首先确定对于每一个特征需要多少的桶bin，然后均分，将属于该桶的样本数据更新为bin的值，最后用直方图表示。（看起来很高大上，其实就是直方图统计，最后我们将大规模的数据放在了直方图中）

直方图算法有几个需要注意的地方：

* 使用bin替代原始数据相当于增加了正则化；
* 使用bin意味着很多数据的细节特征被放弃了，相似的数据可能被划分到相同的桶中，这样的数据之间的差异就消失了；
* bin数量选择决定了正则化的程度，bin越少惩罚越严重，欠拟合风险越高。

直方图算法：

{% asset_img 5.png %}

直方图算法需要注意的地方：

* 构建直方图时不需要对数据进行排序（比XGBoost快），因为预先设定了bin的范围；
* 直方图除了保存划分阈值和当前bin内样本数以外还保存了当前bin内所有样本的一阶梯度和（一阶梯度和的平方的均值等价于均方损失）；
* 阈值的选取是按照直方图从小到大遍历，使用了上面的一阶梯度和，目的是得到划分之后使$\bigtriangleup loss$最大的特征及阈值。

## 5. 优势解读

### 5.1 内存优化

图中表示原始数据的inices和values都用4bytes存储，使用直方图算法不需要存储indices，values转为bin的值最少仅需要1byte（uint8），所以有了8倍内存减小的优势。

{% asset_img 6.png %}

1. 由于使用原始数据到bin的映射，那么存储时只需要存储bin的值；
2. 对于某些特征的数据，它们映射到的bin的数量较少，那么可以用uint8表示bin的值。

### 5.2 带最大深度限制的Leaf-wise

{% asset_img 7.png %}

1. 根据之前介绍的Leaf-wise算法，可以知道Leaf-wise比Level-wise能减少更多的损失，性能更强；
2. 通过设置最大深度约束Leaf-wise的生长有利于减小过拟合风险。

### 5.3 直方图减法

{% asset_img 8.png %}

1. 根据上面直方图算法介绍，我们知道构建bin的时候保存了当前bin内所有样本的一阶梯度和，那么后面划分结点时按照bin的顺序遍历左边加起来，然后用总和减去左边的和，剩下就是右子树的一阶梯度和；
2. 计算复杂度仅与bin的数量有关，为$O(n_{bin})$；
3. 只需做一次减法就得到两棵树的一阶梯度和，那么速度比分别计算左右两边快两倍。

### 5.4 增加缓存命中率

cache miss一般发生在访问的数据随机性很大的任务中，这是由于内存的管理机制决定的，因此如果访问的数据是相邻的或有序的，那么缓存命中率就会提升，缓存命中率提升会增加访问速度，从另一个角度增加计算速度。

在XGBoost中我们计算某个叶结点权重的最优值需要用到落入此结点的所有样本的一阶梯度以及二阶梯度，与此同时，划分依据的特征也是需要遍历的，也就是说，在划分并确定最佳权重的阶段，计算复杂度为$O(n_{data} \times n_{feature})$，而且数据之间没有规律可循，因此缓存命中率低。

{% asset_img 9.png %}

在LightGBM使用基于直方图算法，它是如何增加缓存命中率的？

首先不需要考虑样本的indices了，不需要考虑样本的顺序，仅需要直方图中的数据；其次由于直方图中已经计算了一阶梯度和，而且由于采用了直方图减法，因此需要读取的数据量小而且有序，所以缓存命中率提升。

{% asset_img 10.png %}

### 5.5 支持Category特征

一般来说，可以将Category特征转换为onehot变量作为输入，LightGBM的决策树直接将Category特征加入到判定方法中，减少了计算时间以及存储占用。

{% asset_img 11.png %}

### 5.6 支持分布式并行计算

从三个方面分析并行计算的优势：

* 特征并行Feature Parallelizztion
    * 数据计算和数据交互取决于data
* 数据并行Data Parallelizztion
    * 数据交互取决于feature 
* 投票并行Voting Parallelizztion
    * 减少数据并行中的数据交互

#### 5.6.1 Feature Parallelizztion

很简单，就是将不同的特征给不同的worker。

{% asset_img 12.png %}

#### 5.6.2 Data Parallelizztion

不同的worker分配不同的数据，生成**所有特征**的本地直方图

{% asset_img 13.png %}

#### 5.6.3 Voting Parallelizztion

不同的worker分配不同的数据，增加了Voting阶段，应该是每个worker先选出最佳的几个划分特征，然后集体再voting，再选出集体的最佳的几个特征，最后再集成直方图数据，进行全局划分

{% asset_img 14.png %}

### 5.7 其他优点

{% asset_img 15.png %}

在LightGBM库中使用num_leaves替换最大深度，对应的替换公式如下

{% asset_img 16.png %}

其他优势的说明如下：

{% asset_img 17.png %}

{% asset_img 18.png %}

{% asset_img 19.png %}




