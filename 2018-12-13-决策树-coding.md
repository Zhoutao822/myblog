---
title: 决策树-coding
date: 2018-12-13 16:18:27
categories:
- Coding
tags:
- Code
- Decision Tree
mathjax: true
---

## 1. 数据集说明

### 1.1 多分类数据集-酒类

* 数据来源：`sklearn.datasets.load_wine`；
* 数据集形状：总计178个样本，每个样本由13个属性表示，以及target表示酒类型0-2，三种类别不是均等的，class_0 (59), class_1 (71), class_2 (48)，所有属性值均为number，详情可调用`load_wine()['DESCR']`了解每个属性的具体含义；
* 数据集划分：随机选出20%数据作为测试集，不做验证集要求；
* 性能度量：accuracy或ROC。


[1.10. 决策树](http://sklearn.apachecn.org/#/docs/11)

> 对于拥有大量特征的数据决策树会出现过拟合的现象。获得一个合适的样本比例和特征数量十分重要，因为在高维空间中只有少量的样本的树是十分容易过拟合的。 
> 考虑事先进行降维(PCA，ICA，使您的树更好地找到具有分辨性的特征。 
> 通过export功能可以可视化您的决策树。使用 max_depth=3 作为初始树深度，让决策树知道如何适应您的数据，然后再增加树的深度。
> 请记住，填充树的样本数量会增加树的每个附加级别。使用max_depth来控制输的大小防止过拟合。
> 通过使用 min_samples_split 和 min_samples_leaf 来控制叶节点上的样本数量。当这个值很小时意味着生成的决策树将会过拟合，然而当这个值很大时将会不利于决策树的对样本的学习。所以尝试 min_samples_leaf=5 作为初始值。如果样本的变化量很大，可以使用浮点数作为这两个参数中的百分比。两者之间的主要区别在于 min_samples_leaf 保证叶结点中最少的采样数，而 min_samples_split 可以创建任意小的叶子，尽管在文献中 min_samples_split 更常见。 
> 在训练之前平衡您的数据集，以防止决策树偏向于主导类.可以通过从每个类中抽取相等数量的样本来进行类平衡，或者优选地通过将每个类的样本权重 (sample_weight) 的和归一化为相同的值。还要注意的是，基于权重的预修剪标准 (min_weight_fraction_leaf) 对于显性类别的偏倚偏小，而不是不了解样本权重的标准，如 min_samples_leaf。
> 如果样本被加权，则使用基于权重的预修剪标准 min_weight_fraction_leaf 来优化树结构将更容易，这确保叶节点包含样本权重的总和的至少一部分。
> 所有的决策树内部使用 np.float32 数组 ，如果训练数据不是这种格式，将会复制数据集。
> 如果输入的矩阵X为稀疏矩阵，建议您在调用fit之前将矩阵X转换为稀疏的csc_matrix ,在调用predict之前将 csr_matrix 稀疏。当特征在大多数样本中具有零值时，与密集矩阵相比，稀疏矩阵输入的训练时间可以快几个数量级。