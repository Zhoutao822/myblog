---
title: 语音识别-HMM
date: 2018-11-16 15:33:47
categories:
- Speech Recognition
tags:
- Theory
- HMM
- EM Algorithm
mathjax: true
---

参考：

>《解析深度学习-语音识别实践》第3章 隐马尔可夫模型及其变体
> 西瓜书第7章 贝叶斯分类器
> [机器学习系列之EM算法](https://www.cnblogs.com/Gabby/p/5344658.html)
> [HMM模型和Viterbi算法](https://www.cnblogs.com/Denise-hzf/p/6612212.html)

**语音识别过程：切除首尾端静音->声音划分为帧->对每一帧提取MFCC特征->若干帧对应一个状态->三个状态组成一个音素->若干音素组成单词**

## 1. 马尔可夫链

马尔可夫链是一种离散状态的马尔可夫序列，也是一般性马尔可夫序列的特殊形式。
马尔可夫链的状态空间具有离散和有限性：$q_t \in \{ s^{(j)},j = 1,2,...,N\}$。每一个离散值都与马尔可夫链中的一个状态相关。

一个马尔可夫链$\boldsymbol{q}_1^T = q_1, q_2,...,q_T$，可被转移概率完全表示，定义为

$$
P(q_t=s^{(j)}|q_{t-1}=s^{(i)}) = a_{ij}(t) \quad i,j=1,2,...,N
$$

以及初始状态分布概率。如果这些转移概率与时间$t$无关，则得到齐次马尔可夫链。

（齐次）马尔可夫链的转移概率通常能方便地表示为矩阵形式：

$$
\boldsymbol{A} = [a_{ij}], \quad 其中a_{ij} \geqslant 0 \quad \forall i,j ; \sum^N_{j=1}a_{ij}=1 \quad \forall i
$$

$\boldsymbol{A}$称为马尔可夫链的转移矩阵。给定马尔可夫链的转移概率，则状态输出概率

$$
p_j(t) = P[q_t = s^{(j)}]
$$

<!-- more -->

很容易得到，递归计算

$$
p_i(t+1) = \sum^N_{j=1} a_{ji}p_j(t), \quad \forall i
$$

如果马尔可夫链的状态占有分布式渐进收敛：$p_i(t) \rightarrow \pi(q^{(i)})$，当$t \rightarrow \infty$，我们称$p(s^{(i)})$为马尔可夫链的一个稳态分布。对有稳态分布的马尔可夫链来说，他的转移概率$a_{ij}$必须满足：

$$
\bar{\pi}(s^{(i)}) = \sum^N_{j=1}a_{ji}\bar{\pi}(s^{(j)}), \quad \forall i
$$

马尔可夫链的稳态分布在马尔可夫链蒙特卡洛（MCMC）方法中起着重要作用。这些方法用来模拟（即采样）任意复杂的分布函数，使其能执行很多复杂的统计推断和学习任务，否则这些任务运算困难。MCMC方法的理论基础是马尔可夫链到它的稳态分布$\bar{\pi}(s^{(i)})$的渐进收敛。也就是说，无论初始分布如何，马尔可夫链之于$\bar{\pi}(s^{(i)})$是渐进无偏的。因此，为了从任意的复合分布$p(s)$中采样，可以通过设计合适的转移概率构造一个马尔可夫链，使它的稳态分布为$\bar{\pi}(s) = p(s)$。

三种马尔可夫链的性质：

* 马尔可夫链的状态时长是一个指数或几何级分布：$p_i(d)=C(a_{ii})^{d-1}$，其中归一化常数为$C = 1 - a_{ii}$；
* 平均状态时长为

$$
\bar{d}_i = \sum^{\infty}_{d=1}dp_i(d) = \sum^{\infty}_{d=1}(1-a_{ii})(a_{ii})^{d-1} = \frac{1}{1-a_{ii}}
$$

* 对任意一个服从马尔可夫链的观察序列，若它对应有限长度状态序列$\boldsymbol{q}^T_1$，则其概率很容易计算，是所有马尔可夫链的转移概率的乘积：$P(\boldsymbol{q}^T_1) = \bar{\pi}_{q_1}\prod^{T-1}_{t=1}a_{q_tq_{t+1}}$，其中$\bar{\pi}_{s_1}$使当$t=1$时的初始状态输出概率。

## 2. 序列与模型

马尔可夫链的每一种状态与一种输出（观察值或事件）一一对应，没有随机性。

隐马尔可夫序列在各个状态引入一种随机性，用一个观测的概率分布与每一个状态对应，而不是一个确定的事件或观察值。

{% asset_img hmm.png 隐马尔可夫模型%}

即我们观察到的是$x_i$，而观测值仅由隐藏的状态$y_i$决定，而当前时刻的状态$y_i$仅由前一时刻的状态$y_{i-1}$决定。

### 2.1 隐马尔可夫模型的性质

* 齐次马尔可夫链的转移概率矩阵$\boldsymbol{A}=[a_{ij}] \quad i,j = 1,2,...,N$，其中共有$N$个状态

$$
a_{ij} = P(q_t = j | q_{t-1}=i) \quad i,j = 1,2,...,N
$$

* 马尔可夫链的初始概率：$\pi = [\pi_i] \quad i= 1,2,...,N$，其中$\pi_i = P(q_1 = i)$；
* 观察概率分布为$P(\boldsymbol{o}_t|s^{(i)}) \quad i=1,2,...,N$。若$\boldsymbol{o}_t$是离散的，每个状态对应的概率分布用来描述观察$\{ \boldsymbol{v}_1, \boldsymbol{v}_2,...,\boldsymbol{v}_K\}$的概率：

$$
b_i(k) = P(\boldsymbol{o}_t = \boldsymbol{v}_k|q_t = i) \quad i=1,2,...,N
$$

若观察概率分布是连续的，那么概率密度函数PDF中的参数$\Lambda_i$代表HMM状态$i$的特性

---
在语音处理问题中，我们用HMM下的PDF来描述连续观察向量（$\boldsymbol{o}_t \in \mathbb{R}^D$）的概率分布，其中多元混合高斯分布是最成功、应用最广泛的PDF：

$$
b_i(\boldsymbol{o}_t) = \sum^M_{m=1}\frac{c_{i,m}}{(2\pi)^{D/2}|\boldsymbol{\Sigma}_{i,m}|^{1/2}}\exp[-\frac{1}{2}(\boldsymbol{o}_t - \boldsymbol{\mu}_{i,m})^T\boldsymbol{\Sigma}^{-1}_{i,m}(\boldsymbol{o}_t - \boldsymbol{\mu}_{i,m})]
$$

在混合高斯HMM中，参数集$\Lambda_i$包括混合权重成分$c_{i,m}$，高斯分布均值向量$\boldsymbol{\mu}_{i,m} \in \mathbb{R}^D$与协方差矩阵$\boldsymbol{\Sigma}_{i,m} \in \mathbb{R}^{D \times D}$。

有了模型参数后，高斯HMM可以看作是一个观察值序列$\boldsymbol{o}_t，t =1,2,...,T$的生成器。在$t$时刻，数据根据公式

$$
\boldsymbol{o}_t = \boldsymbol{\mu}_i + \boldsymbol{r}_t(\boldsymbol{\Sigma}_i)
$$

生成，其中时刻$t$的状态$i$取决于马尔可夫链的演变，受$a_{ij}$影响，且

$$
\boldsymbol{r}_t(\boldsymbol{\Sigma}_i) = N(0, \boldsymbol{\Sigma}_i)
$$
是均值为0、依赖序号$i$的IID（独立同分布）的高斯剩余序列。

---

有一个对平稳状态的HMM的简单扩展，可以使其观察序列不再是状态限制下的IID。修改常量$\boldsymbol{\mu}_i$，使其随时间而变化：

$$
\boldsymbol{o}_t = \boldsymbol{g}_t(\Lambda_i) + \boldsymbol{r}_t(\boldsymbol{\Sigma}_i)
$$

在状态$i$下，确定性的时间变化轨迹函数$\boldsymbol{g}_t(\Lambda_i)$中的参数是独立的。这便是高斯趋势HMM，这是一种特殊的非平稳状态的HMM，其中一阶统计量（均值）是随时间变化的。

### 2.2 隐马尔可夫模型似然度的计算

设$\boldsymbol{q}_1^T = (q_1, ..., q_T)$是GMM-HMM中的一个有限长度状态序列，$P(\boldsymbol{o}_1^T, \boldsymbol{q}^T_1)$是观察序列$\boldsymbol{o}_1^T = (\boldsymbol{o}_1,...,\boldsymbol{o}_T)$和状态序列$\boldsymbol{q}^T_1$的联合概率。令$P(\boldsymbol{o}_1^T|\boldsymbol{q}_1^T)$表示状态序列$\boldsymbol{q}_1^T$的条件下生成观察序列$\boldsymbol{o}_1^T$的概率。

在GMM-HMM中条件概率$P(\boldsymbol{o}_1^T|\boldsymbol{q}_1^T)$表示为（这里使用$b_i(\boldsymbol{o}_t)$并不准确，因为状态序列的状态i应该在改变，但是对每一个状态来说是独立同分布，都是一个高斯分布形式）：

$$
P(\boldsymbol{o}_1^T|\boldsymbol{q}_1^T) = \prod^T_{t=1}b_i(\boldsymbol{o}_t)
\\
= \prod^T_{t=1}\sum^M_{m=1}\frac{c_{i,m}}{(2\pi)^{D/2}|\boldsymbol{\Sigma}_{i,m}|^{1/2}}\exp[-\frac{1}{2}(\boldsymbol{o}_t - \boldsymbol{\mu}_{i,m})^T\boldsymbol{\Sigma}^{-1}_{i,m}(\boldsymbol{o}_t - \boldsymbol{\mu}_{i,m})]
$$

另一方面，状态序列$\boldsymbol{q}_1^T$的概率为转移概率乘积

$$
P(\boldsymbol{q}_1^T) = \pi_{q_1}\prod^{T-1}_{t=1}a_{q_tq_{t+1}}
$$

为了记号上的简便，考虑初始状态分布的概率为1（$\pi_{q_1} = 1$）

联合概率$P(\boldsymbol{o}_1^T, \boldsymbol{q}_1^T)$可以通过上式乘积得到

$$
P(\boldsymbol{o}_1^T, \boldsymbol{q}_1^T) = P(\boldsymbol{o}_1^T|\boldsymbol{q}_1^T) P(\boldsymbol{q}_1^T)
$$

原则上可以通过累加状态序列下的联合概率计算总体观察序列似然度

$$
P(\boldsymbol{o}_1^T) = \sum_{\boldsymbol{q}_1^T}P(\boldsymbol{o}_1^T, \boldsymbol{q}_1^T)
$$

然而，在长度为$T$下运算是指数级的复杂度（若状态总计$N$种，那么状态序列的种类为$N^T$），所以不可行。使用前向算法计算，复杂度与$T$是线性的。

### 2.3 计算似然度

首先定义马尔可夫链每个状态$i$下的前向概率（物理意义为在$t$时刻观察序列为$\boldsymbol{o}_1^t$且时刻$t$的状态为$i$的概率）

$$
\alpha_t(i) = P(q_t=i,\boldsymbol{o}_1^t), \quad t = 1,...,T
$$

与后向概率（物理意义为在$t$时刻状态为$i$的条件下，从$t+1$到$T$的观察序列为$\boldsymbol{o}^T_{t+1}$的概率）

$$
\beta_t(i) = P(\boldsymbol{o}^T_{t+1}|q_t=i), \quad t = 1,...,T
$$

前向概率和后向概率递归计算方法：

$$
\alpha_t(j) = \sum^N_{i=1}\alpha_{t-1}(i)a_{ij}b_j(\boldsymbol{o}_t), \quad t = 2,3,...,T; \quad j = 1,2,...,N
\\
\beta_t(i) = \sum^N_{j=1}\beta_{t+1}(j)a_{ij}b_j(\boldsymbol{o}_{t+1}), \quad t = T-1, T-2,...,1; \quad i =1,2,...,N
$$

前向概率的递归计算的物理层面可以理解为：首先考虑到$t-1$时刻，其状态可以取$N$种，然后从$t-1$时刻状态转移到$t$时刻状态$j$，需要转移概率，在状态$j$下的观察值为$\boldsymbol{o}_t$的概率为$b_j(\boldsymbol{o}_t)$。同理对后向概率。

$\alpha$递归式初始值为：

$$
\alpha_1(i) = P(q_1=i,\boldsymbol{o}_1) = P(q_1=i)P(\boldsymbol{o}_1|q_1)=\pi_ib_i(\boldsymbol{o}_1), \quad i = 1,2,...,N
$$

令$\beta$递归式初始值为：

$$
\beta_T(i) = 1, \quad i =1,2,...,N
$$

我们的目标是计算$P(\boldsymbol{o}_1^T)$，先对于每个状态$i$与$t = 1,2,...,T$，计算

$$
P(q_t = i,\boldsymbol{o}_1^T) = P(q_t=i, \boldsymbol{o}_1^t, \boldsymbol{o}^T_{t+1})
\\
= P(q_t = i, \boldsymbol{o}_1^t)P(\boldsymbol{o}^T_{t+1}|\boldsymbol{o_1^t, q_t=i})
\\
= P(q_t = i, \boldsymbol{o}_1^t)P(\boldsymbol{o}^T_{t+1}|q_t=i)
\\
= \alpha_t(i)\beta_t(i)
$$

这样，$P(\boldsymbol{o}_1^T)$可以按照公式计算

$$
P(\boldsymbol{o}_1^T) = \sum^N_{i=1}P(q_t=i,\boldsymbol{o}_1^T) = \sum^N_{i=1}\alpha_t(i)\beta_t(i)
\\
\forall t \in [1,T]
$$

将$t=T$代入上式，可以得出

$$
P(\boldsymbol{o}_1^T) = \sum^N_{i=1}\alpha_T(i)
$$

---

前向概率递归

$$
\alpha_t(j) = P(q_t=j,\boldsymbol{o}_1^t)
\\
= \sum^N_{i=1}P(q_{t-1} = i, q_t = j,\boldsymbol{o}_1^{t-1}, \boldsymbol{o}_t)
\\
= \sum^N_{i=1}P(q_t=j,\boldsymbol{o}_t|q_{t-1} = i, \boldsymbol{o}_1^{t-1})P(q_{t-1} = i, \boldsymbol{o}_1^{t-1})
\\
= \sum^N_{i=1}P(q_t=j,\boldsymbol{o}_t|q_{t-1} = i)\alpha_{t-1}(i)
\\
= \sum^N_{i=1}P(\boldsymbol{o}_t|q_t=j,q_{t-1}=i)P(q_t=j|q_{t-1} = i)\alpha_{t-1}(i)
\\
= \sum^N_{i=1}b_j(\boldsymbol{o}_t)a_{ij}\alpha_{t-1}(i)
$$


后向概率递归

$$
\beta_t(i) = P(\boldsymbol{o}_{t+1}^T|q_t=i)
\\
= \frac{P(\boldsymbol{o}_{t+1}^T, q_t=i)}{P(q_t=i)}
\\
=\frac{\sum^N_{j=1}P(\boldsymbol{o}^T_{t+1}, q_t=i,q_{t+1}=j)}{P(q_t=i)}
\\
= \frac{\sum^N_{j=1}P(\boldsymbol{o}^T_{t+1}| q_t=i,q_{t+1}=j)P(q_t=i,q_{t+1}=j)}{P(q_t=i)}
\\
= \sum^N_{j=1}P(\boldsymbol{o}^T_{t+1}|q_{t+1}=j)\frac{P(q_t=i,q_{t+1}=j)}{P(q_t=i)}
\\
= \sum^N_{j=1} P(\boldsymbol{o}^T_{t+2}, \boldsymbol{o}_{t+1}|q_{t+1} = j)a_{ij}
\\
=\sum^N_{j=1}P(\boldsymbol{o}^T_{t+2}|q_{t+1} = j)P(\boldsymbol{o}_{t+1}|q_{t+1} = j)a_{ij}
\\
= \sum^N_{j=1}\beta_{t+1}(j)b_j(\boldsymbol{o}_{t+1})a_{ij}
$$

## 3. EM算法及其在学习HMM参数中的应用

### 3.1 EM算法

> 期望最大算法（EM算法）是一种从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。

假设我们有一组数据，我们希望计算出这组数据的分布概率，常见的有高斯分布。若这组数据仅属于一个高斯成分，那么我们可以直接计算均值和方差作为高斯分布的无偏估计；若这组数据属于多个高斯成分呢，显然无法计算均值和方差，因为我们不知道哪些数据属于高斯成分1，哪些数据属于高斯成分2...，这是由于隐变量产生了作用，在这个问题中隐变量就是数据属于哪个高斯成分，这个时候EM算法可以起作用了。

令$\boldsymbol{X}$表示已观测变量集，$\boldsymbol{Z}$表示隐变量集，$\Theta$表示模型参数。若欲对$\Theta$做极大似然估计，则应最大化对数似然

$$
LL(\Theta|\boldsymbol{X, Z}) = \ln P(\boldsymbol{X,Z}|\Theta)
$$

由于$\boldsymbol{Z}$是隐变量，上式无法直接求解。但此时可以通过对$\boldsymbol{Z}$计算期望，来最大化已观测数据的对数边际似然

$$
LL(\Theta|\boldsymbol{X}) = \ln P(\boldsymbol{X}|\Theta) = \ln \sum_{\boldsymbol{Z}}P(\boldsymbol{X,Z}|\Theta)
$$

EM算法的基本思想是：若参数$\Theta$已知，则根据训练数据推断出最优隐变量$\boldsymbol{Z}$的值（E步）；反之，若$\boldsymbol{Z}$的值已知，则可方便地对参数$\Theta$做极大似然估计（M步）。

于是，以初始值$\Theta^0$为起点（一般自行设置），迭代执行以下步骤直至收敛：

* 基于$\Theta^t$推断隐变量$\boldsymbol{Z}$的期望，记为$\boldsymbol{Z}^t$；
* 基于已观测变量$\boldsymbol{X}$和$\boldsymbol{Z}^t$对参数$\Theta$做极大似然估计，记为$\Theta^{t+1}$。

---

更进一步，若我们不是取$\boldsymbol{Z}$的期望，而是基于$\Theta^t$计算隐变量$\boldsymbol{Z}$地概率分布$P(\boldsymbol{Z}|\boldsymbol{X},\Theta^t)$，则EM算法为：

* $\boldsymbol{E}$步：以当前参数$\Theta^t$推断隐变量分布$P(\boldsymbol{Z}|\boldsymbol{X},\Theta^t)$，并计算对数似然$LL(\Theta|\boldsymbol{X,Z})$关于$\boldsymbol{Z}$的期望，用$Q$表示

$$
Q(\Theta|\Theta^t) = \mathbb{E}_{\boldsymbol{Z}|\boldsymbol{X},\Theta^t}LL(\Theta|\boldsymbol{X, Z})
$$

* $\boldsymbol{M}$步：寻找参数最大化期望似然

$$
\Theta^{t+1} = \underset{\Theta}{\arg \max}Q(\Theta|\Theta^t)
$$

EM算法的特性：

* EM算法提供的是局部的似然度最优结果，因为仅在一轮的M步中更新参数；
* 对初始值敏感，初始值对最大似然度估计结果影响很大；
* 对完整数据集的选择需要根据实际情况来进行变更；
* 通常寻找一个针对期望值的近似表达式是困难的。

### 3.2 Baum-Welch算法

当隐变量符合马尔可夫链的形式时，EM算法可推导为Baum-Welch算法。下面的推导基于高斯分布HMM，完整数据包含了观测序列和隐马尔可夫链序列，例如$\boldsymbol{y} = [\boldsymbol{o}_1^T, \boldsymbol{q}_1^T]$，我们的目标是最大化观测序列概率$P(\boldsymbol{o}_1^T|\Theta)$（或者其似然值）。

E步中计算的期望，通过隐藏状态序列$\boldsymbol{q}_1^T$来确定，$\Theta，\Theta_0$分别表示当前以及前一轮EM迭代中的HMM参数：

$$
Q(\Theta|\Theta_0) = E[\log P(\boldsymbol{o}_1^T, \boldsymbol{q}_1^T|\Theta)|\boldsymbol{o}_1^T, \Theta_0]
$$

M步中通过最大化$Q(\Theta|\Theta_0)$来完成，这是为了取代直接取最大化$P(\boldsymbol{o}_1^T|\Theta)$，为什么可以取代，这是Baum不等式推导出的结果

$$
\log \frac{P(\boldsymbol{o}_1^T|\Theta)}{P(\boldsymbol{o}_1^T|\Theta_0)} \geqslant Q(\Theta|\Theta_0) - Q(\Theta_0|\Theta_0) \geqslant 0
$$

---

**$\boldsymbol{E}$步骤**

目的简化条件期望值$Q(\Theta|\Theta_0)$，使其变成一个适合直接做最大化的形式。在已知前一轮的参数$\Theta_0$和观察序列$\boldsymbol{o}_1^T$的情况下，下面是基于状态序列$\boldsymbol{q}_1^T$的加权求和的期望值$Q(\Theta|\Theta_0)$

$$
Q(\Theta|\Theta_0) = E[\log P(\boldsymbol{o}_1^T, \boldsymbol{q}_1^T|\Theta)|\boldsymbol{o}_1^T, \Theta_0]
\\
= \sum_{\boldsymbol{q}_1^T}P(\boldsymbol{q}_1^T|\boldsymbol{o}_1^T, \Theta_0)\log P(\boldsymbol{o}_1^T, \boldsymbol{q}_1^T|\Theta)
$$

由于我们假定隐藏序列的状态$i$属于一个高斯成分（多元高斯分布），则其对数似然$N_t(i)$为

$$
N_t(i) = -\frac{D}{2}\log (2\pi) - \frac{1}{2}\log |\boldsymbol{\Sigma}_i|-\frac{1}{2}(\boldsymbol{o}_t-\boldsymbol{\mu}_i)^T\boldsymbol{\Sigma}_i^{-1}(\boldsymbol{o}_t-\boldsymbol{\mu}_i)
$$

由$P(\boldsymbol{q}_1^T) = \prod_{t=1}^{T-1}a_{q_tq_{t+1}}$和$P(\boldsymbol{o}_1^T, \boldsymbol{q}_1^T) = P(\boldsymbol{o}_1^T|\boldsymbol{q}_1^T)P(\boldsymbol{q}_1^T)$，所以

$$
\log P(\boldsymbol{o}_1^T, \boldsymbol{q}_1^T|\Theta) = \sum^T_{t=1}N_t(q_t) + \sum^{T-1}_{t=1}\log a_{q_tq_{t+1}}
$$

于是$Q(\Theta|\Theta_0)$重写为

$$
Q(\Theta|\Theta_0) = \sum_{\boldsymbol{q}_1^T}P(\boldsymbol{q}_1^T|\boldsymbol{o}_1^T, \Theta_0)\sum^T_{t=1}N_t(q_t) + \sum_{\boldsymbol{q}_1^T}P(\boldsymbol{q}_1^T|\boldsymbol{o}_1^T, \Theta_0)\sum^{T-1}_{t=1}\log a_{q_tq_{t+1}}
$$

其中第一部分可写为

$$
Q_1(\Theta|\Theta_0) = \sum^N_{i=1} \{ \sum_{\boldsymbol{q}_1^T}P(\boldsymbol{q}_1^T|\boldsymbol{o}_1^T, \Theta_0)\sum^T_{t=1}N_t(q_t) \} \delta_{q_t,i}
$$

第二部分

$$
Q_2(\Theta|\Theta_0) = \sum^N_{i=1}\sum^N_{j=1} \{ \sum_{\boldsymbol{q}_1^T}P(\boldsymbol{q}_1^T|\boldsymbol{o}_1^T, \Theta_0)\sum^{T-1}_{t=1}\log a_{q_tq_{t+1}} \} \delta_{q_t,i} \delta_{q_{t+1},j}
$$

$\delta_{q_t, i}$是克罗内克函数，当$q_t = i$取1，否则取0。

通过代换求和可以使用

$$
\sum_{\boldsymbol{q}_1^T}P(\boldsymbol{q}_1^T|\boldsymbol{o}_1^T, \Theta_0) \delta_{q_t,i} = P(q_t=i|\boldsymbol{o}_1^T,\Theta_0)
$$

通过上式简化$Q_1$和$Q_2$

$$
Q_1(\Theta|\Theta_0) =\sum^N_{i=1}\sum^T_{t=1}P(q_t=i|\boldsymbol{o}_1^T,\Theta_0)N_t(i)
\\
Q_2(\Theta|\Theta_0) = \sum^N_{i=1}\sum^N_{j=1}\sum^{T-1}_{t=1} P(q_t=i,q_{t+1}=j|\boldsymbol{o}_1^T,\Theta_0)\log a_{ij}
$$

因为$Q_1(\Theta|\Theta_0)$只包含高斯参数，$Q_2(\Theta|\Theta_0)$只包含马尔科夫链参数，两个式子可以分别最大化。也就是说在最大化$Q(\Theta|\Theta_0)$时，公式中的权重，或者说$\gamma_t(i) = P(q_t=i|\boldsymbol{o}_1^T,\Theta_0)$和$\xi_t(i,j) = P(q_t=i,q_{t+1}=j|\boldsymbol{o}_1^T,\Theta_0)$，可以分别被认为是对方的已知常数。因此可以用前后向概率来计算。高斯HMM中的后验状态转移概率为

$$
\xi_t(i,j) = \frac{\alpha_t(i)\beta_{t+1}(j)a_{ij}\exp(N_{t+1}(j))}{P(\boldsymbol{o}_1^T|\Theta_0)}
\\
t = 1,2,...,T-1
\\
P(\boldsymbol{o}_1^T|\Theta_0) = \sum^N_{i=1}\sum^N_{j=1}\alpha_t(i)\beta_{t+1}(j)a_{ij}\exp(N_{t+1}(j))
$$

后验状态占用概率为

$$
\gamma_t(i) = \sum^N_{j=1}\xi_t(i,j)
\\
t = 1,2,...,T-1
$$

$\gamma_T(i)$则可以通过它的特定定义得到：

$$
\gamma_T(i) = P(q_T=i|\boldsymbol{o}_1^T, \Theta_0) = \frac{P(q_T=i,\boldsymbol{o}_1^T| \Theta_0)}{P(\boldsymbol{o}_1^T| \Theta_0)} = \frac{\alpha_T(i)}{P(\boldsymbol{o}_1^T| \Theta_0)}
$$

对从左到右传播的HMM，在$i=N$时，$\gamma_T(i)$只有一个值1，其余值为0。因为我们将状态序列转换成了在状态$i$或状态对$(i,j)$上，因此得到了极大的简化。

**$\boldsymbol{M}$步骤**

高斯HMM马尔可夫链转移概率的重估公式通过令$\frac{\partial Q_2}{\partial a_{ij}} = 0$得到，对$Q_2$以及对$i,j=1,2,...,N$，使其服从$\sum^N_{j=1}a_{ij}=1$的约束条件。标准拉格朗日乘子法使重估公式变为

$$
\hat{a}_{ij} = \frac{\sum^{T-1}_{t=1}\xi_t(i,j)}{\sum^{T-1}_{t=1}\gamma_t(i)}
\\
其中\xi_t(i,j)和\gamma_t(i)根据E步中公式计算
$$

$Q_1$的等价优化目标函数为

$$
Q_1(\boldsymbol{\mu}_i, \boldsymbol{\Sigma}_i) = \sum^N_{i=1}\sum^{T}_{t=1}\gamma_t(i)(\boldsymbol{o}_t-\boldsymbol{\mu}_i)^T\boldsymbol{\Sigma}_i^{-1}(\boldsymbol{o}_t-\boldsymbol{\mu}_i) - \frac{1}{2}\log |\boldsymbol{\Sigma}_i|
$$

所以协方差矩阵的重估公式通过令下式为0得到
$$
\frac{\partial Q_1}{\partial \boldsymbol{\Sigma}_i} = 0 \quad i = 1,2,...,N
$$

为了解上面的方程，令$\boldsymbol{K} = \boldsymbol{\Sigma}^{-1}$（为了简化，忽略状态角标$i$），之后将$Q_1$视为$\boldsymbol{K}$的一个方程。已知$\log|\boldsymbol{K}|$对$\boldsymbol{K}$的第$lm$项系数求导，其结果是方差矩阵$\boldsymbol{\Sigma}$的第$lm$项系数，即$\sigma_{lm}$，那么可以将$\frac{\partial Q_1}{\partial k_{lm}} = 0$化简为

$$
\sum^T_{t=1}\gamma_t(i)\{ \frac{1}{2}\sigma_{lm} - \frac{1}{2}(\boldsymbol{o}_t-\boldsymbol{\mu}_i)_l(\boldsymbol{o}_t-\boldsymbol{\mu}_i)_m \} = 0
\\
l,m = 1,2,...,D
$$

将上式写成矩阵形式

$$
\hat{\boldsymbol{\Sigma}}_i = \frac{\sum^T_{t=1}\gamma_t(i)(\boldsymbol{o}_t - \hat{\boldsymbol{\mu}}_i)(\boldsymbol{o}_t - \hat{\boldsymbol{\mu}}_i)^T}{\sum^T_{t=1}\gamma_t(i)}
\\
i=1,2,...,N
$$

其中高斯HMM均值向量$\hat{\boldsymbol{\mu}}_i$的重估公式为

$$
\hat{\boldsymbol{\mu}}_i = \frac{\sum^T_{t=1}\gamma_t(i)\boldsymbol{o}_t}{\sum^T_{t=1}\gamma_t(i)}
$$

上面的推导针对单高斯HMM的情况。针对GMM-HMM的EM算法，通常认为每一帧中每一状态上的高斯成分是一个隐变量。

## 4. 用于解码HMM状态序列的维特比算法

> 在关于数个阶段之间互不关联的优化问题中，不管初始状态或者初始决策是什么，剩余的决策应该包含一个最优的方法用于选择从第一个选择得到的状态中去得到剩余的决策。

马尔可夫决策过程由两部分参数决定，第一部分是转移概率

$$
P^k_{ij}(n) = P(state_j,stage_{n+1}|state_i,stage_n,decision_k)
$$

其中，系统的当前状态只依赖于系统的前一阶段所处的状态以及在那个状态上所采取的决策。第二部分参数提供了决策收益

$$
R^k_i(n) = 在n阶段和状态i上，采用决策k时得到的收益
$$

下面定义$F(n,i)$作为阶段$n$和状态$i$上最优决策被采取时的平均总收益：

$$
F(n,i) = \underset{k}{\max}\{ R^k_i(n)+\sum_j P^k_{ij}(n)F(n+1,i) \}
$$

特别地，当$n=N$（最后阶段），状态$i$的总收益

$$
F(N,i) = \underset{k}{\max} R^k_i(n)
$$

最优决策序列可以在最后一轮递归计算之后进行回溯。

---

在给定一组观察序列$\boldsymbol{o}^T_1 = \boldsymbol{o}_1,\boldsymbol{o}_2,...,\boldsymbol{o}_T$的情况下，如何高效地找到最优地HMM状态序列。

对一个状态转移概率$a_{ij}$给定地HMM，设状态输出概率分布为$b_i(\boldsymbol{o}_t)$，令$\delta_i(t)$表示部分观察序列$\boldsymbol{o}_1^t$到达时间$t$，同时相应地HMM状态序列在该事件处在状态$i$时地联合似然度的最大值：

$$
\delta_i(t) = \underset{q_1,q_2,...,q_{t-1}}{\max} P(\boldsymbol{o}^t_1,q_1^{t-1},q_t=i)
$$

在最终阶段$t=T$时，我们有最优函数$\delta_i(T)$，这个可以通过递归计算得到

$$
\delta_j(t+1) = \underset{i}{\max} \delta_i(t)a_{ij}b_j(\boldsymbol{o}_{t+1})
$$

完整的维特比算法要求递归初始化、递归终止条件和路线回溯。结果包含最大联合似然度观察和状态序列$P^*$，以及相应地状态转移路径$q^*(t)$。
