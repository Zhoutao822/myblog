---
title: 生成式对抗网络
date: 2019-01-03 21:26:22
categories:
- Deep Learning
tags:
- Theory
- GAN
mathjax: true
---

**道高一尺魔高一丈，魔高一尺道高一丈**

参考：

> [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)
> [[GAN学习系列] 初识GAN](https://juejin.im/post/5bd07e26e51d457a7c7bbc31)
> [[GAN学习系列2] GAN的起源](https://juejin.im/post/5bdd70886fb9a049f912028d)
> [令人拍案叫绝的Wasserstein GAN](https://zhuanlan.zhihu.com/p/25071913)
> [Tips and tricks to make GANs work](https://github.com/soumith/ganhacks)
> [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004v1.pdf)


GAN，即生成式对抗网络，是一个生成模型，也是半监督和无监督学习模型，它可以在**不需要大量标注数据**的情况下学习深度表征。最大的特点就是提出了一种让两个深度网络对抗训练的方法。

GAN 主要就是两个网络组成，生成器网络(Generator)和判别器网络(Discriminator)，通过这两个网络的互相博弈，让生成器网络最终能够学习到输入数据的分布，这也就是 GAN 想达到的目的：学习输入数据的分布。

<!-- more -->

## 1. 基本原理

{% asset_img 1.png %}

* D 是判别器，负责对输入的真实数据和由 G 生成的假数据进行判断，其输出是 0 和 1，即它本质上是一个二值分类器，目标就是对输入为真实数据输出是 1，对假数据的输入，输出是 0；
* G 是生成器，它接收的是一个随机噪声，并生成图像。

在训练的过程中，G 的目标是尽可能生成足够真实的数据去迷惑 D，而 D 就是要将 G 生成的图片都辨别出来，这样两者就是互相博弈，最终是要达到一个平衡，也就是纳什均衡。

需要注意的是，在原始GAN中，生成器接收的是随机噪声（大小可能在$[-1， 1]$之间），输出的是具有真实图片风格（不完全相同）的图片，也不需要标签，也就是说从噪声到图片的映射是不可描述的，而学习到的**输入数据的特征**仅能够作用在随机噪声上，因此原始GAN的作用被限制了，如果能将生成器的输入为某个与真实图片相关的特征映射，那么我们就可以利用这个生成器来进行图片风格迁移。

## 2. GAN特点

优：

* 对于生成式模型来说，可以类比`语音识别-RBM和DBN`以及`语音识别-HMM`，RBM和HMM都是基于隐变量状态来描述观察变量，而GAN可以不考虑隐变量而是通过神经网络来描述生成器和判别器，这也就意味着GAN不需要对状态作近似推断，也不依赖马尔可夫链，仅需要反向传播即可训练网络，相比其他生成模型（VAE、玻尔兹曼机），可以生成更好的生成样本；
* 理论上，只要是可微分函数都可以用于构建 D 和 G，因为能够与深度神经网络结合做深度生成式模型；
* G 的参数更新不是直接来自数据样本，而是使用来自 D 的反向传播；
* GAN 是一种半监督学习模型，对训练集不需要太多有标签的数据；
* 没有必要遵循任何种类的因子分解去设计模型，所有的生成器和鉴别器都可以正常工作。

劣：

* 可解释性差，生成模型的分布$P_g(G)$没有显式的表达；
* 比较难训练，D 与 G 之间需要很好的同步，例如 D 更新 k 次而 G 更新一次；
* 训练 GAN 需要达到纳什均衡，有时候可以用梯度下降法做到，有时候做不到，我们还没有找到很好的达到纳什均衡的方法，所以训练 GAN 相比 VAE 或者 PixelRNN 是不稳定的，但我认为在实践中它还是比训练玻尔兹曼机稳定的多；
* 它很难去学习生成离散的数据，就像文本；
* 相比玻尔兹曼机，GANs 很难根据一个像素值去猜测另外一个像素值，GANs 天生就是做一件事的，那就是一次产生所有像素，你可以用 BiGAN 来修正这个特性，它能让你像使用玻尔兹曼机一样去使用 Gibbs 采样来猜测缺失值；
* 训练不稳定，G 和 D 很难收敛；
* 训练还会遭遇梯度消失、模式崩溃的问题；
* 缺乏比较有效的直接可观的评估模型生成效果的方法。

### 2.1 为什么训练会出现梯度消失和模式崩溃

梯度消失和模式奔溃其实就是这种情况下的两个结果，分别对应 D 和 G 是强大的一方的结果。

1. 对于梯度消失的情况是**D 越好，G 的梯度消失越严重**，因为 G 的梯度更新来自 D，而在训练初始阶段，G 的输入是随机生成的噪声，肯定不会生成很好的图片，D 会很容易就判断出来真假样本，也就是 D 的训练几乎没有损失，也就没有有效的梯度信息回传给 G 让 G 去优化自己。这样的现象叫做 gradient vanishing，梯度消失问题。
2. 对于模式奔溃（mode collapse）问题，主要就是**G 比较强，导致 D 不能很好区分出真实图片和 G 生成的假图片**，而如果此时 G 其实还不能完全生成足够真实的图片的时候，但 D 却分辨不出来，并且给出了正确的评价，那么 G 就会认为这张图片是正确的，接下来就继续这么输出这张或者这些图片，然后 D 还是给出正确的评价，于是两者就是这么相互欺骗，这样 G 其实就只会输出固定的一些图片，导致的结果除了生成图片不够真实，还有就是多样性不足的问题。

### 2.2 为什么GAN不适合处理文本数据

1. 文本数据相比较图片数据来说是离散的，因为对于文本来说，通常需要将一个词映射为一个高维的向量，最终预测的输出是一个one-hot向量，假设 softmax 的输出是$(0.2， 0.3， 0.1，0.2，0.15，0.05)$，那么变为 onehot是$(0，1，0，0，0，0)$，如果softmax输出是$(0.2， 0.25， 0.2， 0.1，0.15，0.1 )$，one-hot 仍然是$(0， 1， 0， 0， 0， 0)$，所以对于生成器来说，G 输出了不同的结果, 但是 D 给出了同样的判别结果，并不能将梯度更新信息很好的传递到 G 中去，所以 D 最终输出的判别没有意义。
2. GAN 的损失函数是 JS 散度，JS 散度不适合衡量不想交分布之间的距离。（WGAN 虽然使用 wassertein 距离代替了 JS 散度，但是在生成文本上能力还是有限，GAN 在生成文本上的应用有 seq-GAN,和强化学习结合的产物）

### 2.3 为什么GAN中的优化器不常用SGD

1. SGD 容易震荡，容易使 GAN 的训练更加不稳定。
2. GAN 的目的是在高维非凸的参数空间中找到纳什均衡点，GAN 的纳什均衡点是一个鞍点，但是 SGD 只会找到局部极小值，因为 SGD 解决的是一个寻找最小值的问题，但 GAN 是一个博弈问题。

## 3. 训练技巧

### 3.1 对输入进行规范化 

* 将输入规范化到 -1 和 1 之间
* G 的输出层采用Tanh激活函数

### 3.2 采用修正的损失函数

在原始 GAN 论文中，损失函数 G 是要$\min \log(1-D)$, 但实际使用的时候是采用$\max \log(D)$，作者给出的原因是前者会导致梯度消失问题。
但实际上，即便是作者提出的这种实际应用的损失函数也是存在问题，即模崩溃的问题，在接下来提出的 GAN 相关的论文中，就有不少论文是针对这个问题进行改进的，如 WGAN 模型就提出一种新的损失函数。

### 3.3 从球体上采样噪声

* 不要采用均匀分布来采样
* 从高斯分布中采样得到随机噪声
* 当进行插值操作的时候，从大圆进行该操作，而不要直接从点 A 到 点 B 直线操作，如下图所示

{% asset_img 2.png %}

### 3.4 BatchNorm

* 采用 mini-batch BatchNorm，要保证每个 mini-batch 都是真实图片或者都是生成图片
* 不采用 BatchNorm 的时候，可以采用 instance normalization（对每个样本的规范化操作，减均值除以标准差）
* 可以使用虚拟批量归一化(virtural batch normalization):开始训练之前预定义一个 batch R，对每一个新的 batch X，都使用 R+X 的级联来计算归一化参数

### 3.5 避免稀疏的梯度：ReLU、MaxPool

* 稀疏梯度会影响 GAN 的稳定性
* 在 G 和 D 中采用 LeakyReLU 代替 Relu 激活函数
* 对于下采样操作，可以采用平均池化(Average Pooling) 和 Conv2d+stride 的替代方案
* 对于上采样操作，可以使用 [PixelShuffle](https://arxiv.org/abs/1609.05158), ConvTranspose2d + stride

### 3.6 标签的使用

* 标签平滑。也就是如果有两个目标标签，假设真实图片标签是 1，生成图片标签是 0，那么对每个输入例子，如果是真实图片，采用 0.7 到 1.2 之间的一个随机数字来作为标签，而不是 1；一般是采用单边标签平滑
* 在训练 D 的时候，偶尔翻转标签
* 有标签数据就尽量使用标签

### 3.7 DCGAN/混合模型

* 尽量使用DCGAN
* 如果DCGAN不稳定，使用混合模型：KL+GAN或者VAE+GAN

### 3.8 使用RL的稳定性tricks

* 训练过程回放
  * 缓存之前的生成器生成的结果，偶尔展示出来
  * 保存G和D的检查点，偶尔将当前G和D置换为以前保存的G和D，以训练几轮
* All stability tricks that work for deep deterministic policy gradients

### 3.9 使用 Adam 优化器

* 遵守Adam规则
* D使用SGD，G使用Adam

### 3.10 尽早追踪失败的原因

* D 的 loss 变成 0，那么这就是训练失败了
* 检查规范的梯度：如果超过 100，那出问题了
* 如果训练正常，那么 D loss 有低方差并且随着时间降低
* 如果 g loss 稳定下降，那么它是用糟糕的生成样本欺骗了 D

### 3.11 不要通过统计学来平衡 loss（除非你有一个好的理由）

* 不要试图寻找一个训练轮数以避免模式崩溃（无用的做法）
* 如果要这样做，需要制定一个准则而非依靠直觉

```
while lossD > A:
  train D
while lossG > B:
  train G
```

### 3.12 给输入添加噪声，随时间衰减

* 给 D 的输入添加人为的噪声
  * [www.inference.vc/instance-no…](https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/)
  * [openreview.net/forum?id=Hk…](https://openreview.net/forum?id=Hk4_qw5xe)
* 给 G 的每层都添加高斯噪声

### 3.13 对于 Conditional GANs 的离散变量

* 使用一个 Embedding 层
* 对输入图片添加一个额外的通道
* 保持 embedding 低维并通过上采样操作来匹配图像的通道大小

### 3.14 在 G 的训练和测试阶段使用 Dropouts

* 以 dropout 的形式提供噪声(50%的概率)
* 训练和测试阶段，在 G 的几层使用

## 4. 对抗样本

**对抗样本(adversarial example)，它是指经过精心计算得到的用于误导分类器的样本**。例如下图就是一个例子，左边是一个熊猫，但是添加了少量随机噪声变成右图后，分类器给出的预测类别却是长臂猿，但视觉上左右两幅图片并没有太大改变。

{% asset_img 3.png %}

这是因为图像分类器本质上是高维空间的一个复杂的决策边界。当然涉及到图像分类的时候，由于是高维空间而不是简单的两维或者三维空间，我们无法画出这个边界出来。但是我们可以肯定的是，训练完成后，分类器是无法泛化到所有数据上，除非我们的训练集包含了分类类别的所有数据，但实际上我们做不到。而做不到泛化到所有数据的分类器，其实就会过拟合训练集的数据，这也就是我们可以利用的一点。

我们可以给图片添加一个非常接近于 0 的随机噪声，这可以通过控制噪声的 L2 范数来实现。L2 范数可以看做是一个向量的长度，这里有个诀窍就是图片的像素越多，即图片尺寸越大，其平均 L2 范数也就越大。因此，当添加的噪声的范数足够低，那么视觉上你不会觉得这张图片有什么不同，正如上述右边的图片一样，看起来依然和左边原始图片一模一样；但是，在向量空间上，添加噪声后的图片和原始图片已经有很大的距离了。

因为在 L2 范数看来，对于熊猫和长臂猿的决策边界并没有那么远，添加了非常微弱的随机噪声的图片可能就远离了熊猫的决策边界内，到达长臂猿的预测范围内，因此欺骗了分类器。

除了这种简单的添加随机噪声，还可以通过图像变形的方式，使得新图像和原始图像视觉上一样的情况下，让分类器得到有很高置信度的错误分类结果。这种过程也被称为对抗攻击(adversarial attack)，这种生成方式的简单性也是给 GAN 提供了解释。

## 5. 生成对抗网络GAN

生成器G与判别器D组合起来就是GAN，其目标是

$$
\underset{G}{\min} \underset{D}{\max} V(D, G) = \mathbb{E}_{\boldsymbol{x} \sim p_{data}(\boldsymbol{x})}[\log D(\boldsymbol{x})] + \mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log (1 - D(G(\boldsymbol{z})))]
$$

对于判别器D来说，其更新梯度为

$$
\bigtriangledown_{\theta_d}\frac{1}{m}\sum^m_{i=1}[\log D(\boldsymbol{x}^{(i)} ) + \log(1 - D(G(\boldsymbol{z}^{(i)})))]
$$

对于生成器G来说，其更新梯度为

$$
\bigtriangledown_{\theta_g}\frac{1}{m} \sum^m_{i=1}\log(1-D(G(\boldsymbol{z}^{(i)})))
$$

这里根据它们的损失函数分析下，G 网络的训练目标就是让**D(G(z)) 趋近于 1**，这也是让其 loss 变小的做法；而 D 网络的训练目标是区分真假数据，自然是让**D(x) 趋近于 1，而 D(G(z)) 趋近于 0**。这就是两个网络相互对抗，彼此博弈的过程了。

{% asset_img 4.png %}

上图中，黑色曲线表示输入数据 x 的实际分布，绿色曲线表示的是 G 网络生成数据的分布，我们的目标自然是希望着两条曲线可以相互重合，也就是两个数据分布一致了。而蓝色的曲线表示的是生成数据对应于 D 的分布。

在 a 图中是刚开始训练的时候，D 的分类能力还不是最好，因此有所波动，而生成数据的分布也自然和真实数据分布不同，毕竟 G 网络输入是随机生成的噪声；到了 b 图的时候，D 网络的分类能力就比较好了，可以看到对于真实数据和生成数据，它是明显可以区分出来，也就是给出的概率是不同的；

而绿色的曲线，即 G 网络的目标是学习真实数据的分布，所以它会往蓝色曲线方向移动，也就是 c 图了，并且因为 G 和 D 是相互对抗的，当 G 网络提升，也会影响 D 网络的分辨能力。论文中，Ian Goodfellow 做出了证明，当假设 G 网络不变，训练 D 网络，最优的情况会是：

$$
D_G^*(\boldsymbol{x}) = \frac{p_{data}(\boldsymbol{x})}{p_{data}(\boldsymbol{x}) + p_g(\boldsymbol{x})}
$$

也就是当生成数据的分布$p_g(x)$趋近于真实数据分布$p_{data}(x)$的时候，D 网络输出的概率$D_G^*(x)$会趋近于 0.5，也就是 d 图的结果，这也是最终希望达到的训练结果，这时候 G 和 D 网络也就达到一个平衡状态。

## 6. 算法

论文给出的算法实现过程如下所示

{% asset_img 5.png %}

这里包含了一些训练的技巧和方法：

1. 首先 G 和 D 是同步训练，但两者训练次数不一样，通常是**D 网络训练 k 次后，G 训练一次**。主要原因是 GAN 刚开始训练时候会很不稳定；
2. D 的训练是**同时输入真实数据和生成数据来计算 loss，而不是采用交叉熵（cross entropy）分开计算**。不采用 cross entropy 的原因是这会让$D(G(z))$变为 0，导致没有梯度提供给 G 更新，而现在 GAN 的做法是会收敛到 0.5；
3. 实际训练的时候，作者是采用$-\log(D(G(\boldsymbol{z})))$来代替$\log(1-D(G(\boldsymbol{z})))$，这是希望在训练初始就可以加大梯度信息，这是因为初始阶段 D 的分类能力会远大于 G 生成足够真实数据的能力，但这种修改也将让整个 GAN 不再是一个完美的零和博弈。


