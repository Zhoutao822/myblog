---
title: 深度学习-正则化
date: 2018-11-29 09:07:16
categories:
- deep learning
tags:
- theory
- regularization
mathjax: true
---

参考：

> [《深度学习》第7章 深度学习中的正则化](https://github.com/exacity/deeplearningbook-chinese)

本章部分内容与`深度学习-实际问题`交叉。

机器学习的一个核心问题是设计一个不仅在训练数据上表现好，并且能在新输入上泛化好的算法。在机器学习中，许多策略显式地被设计来减少测试误差（可能会以增大训练误差为代价），这些策略被统称为正则化。

<!-- more -->

## 1. 参数范数惩罚

对优化目标$J$添加一个参数惩罚项$\Omega(\theta)$，正则化后的目标函数记为

$$
\hat{J}(\theta;\boldsymbol{X, y}) = J(\theta;\boldsymbol{X, y}) + \alpha\Omega(\theta)
$$

其中$\alpha \in [0, \infty)$是权衡范数惩罚项$\Omega$和目标函数$J$相对贡献的超参数。显然，$\alpha$为0表示没有正则化，$\alpha$越大正则化惩罚越大。

通常只对**权重**做惩罚而不对偏置做正则惩罚，一是因为对所有权重进行等比例缩放可以实现偏置的修正，所以对偏置惩罚是多余的；二是因为正则化偏置参数可能会导致明显的欠拟合。

### 1.1 $L^2$参数正则化

即使用$L_2$范数作为正则项$\Omega(\theta) = \frac{1}{2}||\boldsymbol{w}||^2_2$，使权重更接近原点。其目标函数为

$$
\tilde{J}(\boldsymbol{w};\boldsymbol{X,y}) = \frac{\alpha}{2}\boldsymbol{w}^T\boldsymbol{w} + J(\boldsymbol{w};\boldsymbol{X,y})
$$

$L_2$正则化会根据$\frac{\lambda_i}{\lambda_i + \alpha}$因子缩放与$\boldsymbol{H}$第$i$个特征向量对齐的$\boldsymbol{w}^*$的分量。

{% asset_img l1l2.jpg 正则化 %}

沿着$\boldsymbol{H}$特征值较大的方向（如$\lambda_i \gg \alpha$）正则化的影响较小，而$\lambda_i \ll \alpha$会收缩到几乎为0（但不是0）。
只有在显著减小目标函数方向上的参数会保留得相对完好。在无助于目标函数减小的方向上改变参数不会显著增加梯度。这种不重要的方向对应的分量会在训练过程中因正则化而衰减掉。

对于线性回归而言，代价函数是

$$
(\boldsymbol{Xw} - \boldsymbol{y})^T(\boldsymbol{Xw} - \boldsymbol{y})
$$

添加$L^2$正则项后，目标函数变为

$$
(\boldsymbol{Xw} - \boldsymbol{y})^T(\boldsymbol{Xw} - \boldsymbol{y}) + \frac{1}{2}\alpha\boldsymbol{w}^T\boldsymbol{w}
$$

那么方程解从

$$
\boldsymbol{w} = (\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}
$$

变成了

$$
\boldsymbol{w} = (\boldsymbol{X}^T\boldsymbol{X} + \alpha\boldsymbol{I})^{-1}\boldsymbol{X}^T\boldsymbol{y}
$$

由于$\boldsymbol{X}^T\boldsymbol{X}$对角项对应每个输入特征的方差，相当于我们对每一个方差都增加了一个相同的值$\alpha$，那么对$\boldsymbol{w}$来说，对应的权重会减小，但是由于每个特征的方差都是不同的，那么增加的值相对于原始方差是有差异的，若原始方差相对于$\alpha$就很大，那么对应的权重减幅较小，原始方差相对于增加的值很小，那么受到这个新增的值的影响，对应的权重减幅很大，几乎接近0但是不会为0。

### 1.2 $L^1$参数正则化 

$L_1$范数正则化，正则项为

$$
\Omega(\theta) = ||\boldsymbol{w}||_1 = \sum_i|w_i|
$$

同理，其目标函数为

$$
\tilde{J}(\boldsymbol{w};\boldsymbol{X, y}) = \alpha||\boldsymbol{w}||_1 + J(\boldsymbol{w};\boldsymbol{X, y})
$$

对于每一维$i$：

$$
w_i = sign(w_i^*)\max \{ |w_i^*| - \frac{\alpha}{H_{i,i}}, 0 \}
$$

显然，当$w_i^* \leqslant \frac{\alpha}{H_{i,i}}$的时候，正则化会使$w_i$变成0，也就是说$L^1$正则化会产生更加**稀疏**的解。因此可以使用$L^1$正则化实现降维或者特征选择。

## 2. 作为约束的范数惩罚

上面介绍的参数范数惩罚未对正则项进行约束，如果我们想约束$\Omega$小于某个常数$k$，往往我们需要使用KKT条件（参考`支持向量机`）

$$
L(\boldsymbol{\theta}, \alpha;\boldsymbol{X, y}) = J(\boldsymbol{\theta;X,y}) + \alpha(\Omega(\theta) - k)
$$

这个约束问题的解由下式给出

$$
\boldsymbol{\theta}^* = \underset{\boldsymbol{\theta}}{\arg \min} \underset{\alpha,\alpha \geqslant 0}{\max} L(\boldsymbol{\theta}, \alpha)
$$

通过设置$k$，我们可以限制$L^2$范数在一个球内或者$L^1$范数的一个限制区域内。

## 3. 正则化和欠约束问题

对矩阵$\boldsymbol{X}^T\boldsymbol{X}$求逆的前提是奇异的，那么对于那些非奇异矩阵，许多正则化方法对应求逆$\boldsymbol{X}^T\boldsymbol{X} + \alpha\boldsymbol{I}$，那么可以保证矩阵是奇异的。

同样的我们可以使用Moore-Penrose伪逆求解

$$
\boldsymbol{X}^+ = \underset{\alpha \searrow 0}{\lim} (\boldsymbol{X}^T\boldsymbol{X} + \alpha\boldsymbol{I})^{-1}\boldsymbol{X}^T
$$

实际计算没有基于这个定义，而是使用奇异值分解

$$
\boldsymbol{A}^+ = \boldsymbol{VD}^+\boldsymbol{U}^T
$$

其中矩阵$\boldsymbol{U,D,V}$是矩阵$\boldsymbol{A}$奇异值分解后得到的矩阵，对角矩阵$\boldsymbol{D}$的伪逆$\boldsymbol{D}^+$是其非零元素取倒数之后再转置得到的。


## 4. 数据集增强

让模型泛化能力更强的最好办法就是使用更多的数据进行训练，但是实际上我们的数据集往往是有限的。解决这个问题的一种方法是创建假的数据添加到训练集中。对于一些特定的机器学习任务，创建新的假数据相当简单。

1. 图像识别，对于图像来说，平移，旋转或缩放都是有效的，但是需要注意比如识别手写数字“6”和“9”，这里旋转180°是不合适的；
2. 语音任务，人为手动在输入层注入噪声。

## 5. 噪声鲁棒性

向输入添加方差极小的噪声等价于对权重施加范数惩罚。在一般情况下，注入噪声远比简单地收缩参数强大，特别是噪声被添加进隐藏单元。比如dropout算法就是这种做法地主要发展方向。

假设对网络的权重添加随机扰动$\epsilon_{\boldsymbol{w}} \in N(\boldsymbol{\epsilon};0,\eta\boldsymbol{I})$，那么我们的目标函数变为：

$$
\tilde{J}_{\boldsymbol{W}} = \mathbb{E}_{p(\boldsymbol{x}, y, \epsilon_\boldsymbol{W})}[(\hat{y}_{\epsilon_\boldsymbol{W}}(\boldsymbol{x}) - y)^2]
$$

它推动模型进入对权重小的变化相对不敏感的区域，找到的点不只是极小点，还是由平坦区域所包围的极小点。

### 5.1 向输出目标注入噪声

大多数数据集的$y$标签都有一定错误。错误的$y$不利于最大化似然对数。如何避免，使用一些小常数$\epsilon$，训练集标记$y$是正确的概率是$1-\epsilon$。

例如，**标签平滑**通过把确切分类目标从0到和1替换成$\frac{\epsilon}{k-1},1-\epsilon$，正则化具有$k$个输出的softmax函数的模型。使用softmax和明确的最大似然学习可能永远不会收敛-softmax函数永远无法真正预测0概率或1概率，因此预测更极端。通过使用权重衰减等其他正则化册率能够防止这种情况发生。

## 6. 半监督学习

参考`语音识别-RBM和DBN`，通过预训练获得输入数据的统计特征。在预训练过程中使用大量的未标记数据。

## 7. 多任务学习

多任务学习是通过合并几个任务中的样例来提高泛化的一种方式。当模型的一部分被多个额外的任务共享时，这部分将被约束为良好的值（共享合理），通常会带来更好的泛化能力。

{% asset_img multi-task_learning.png 多任务学习 %}

该模型通常可以分为两类参数：

1. 具体任务的参数（从各自任务的样本中实现良好的泛化）；
2. 所有任务共享的通用参数（从所有任务的汇集数据中获益），前提是不同的任务之间存在某些统计关系的假设是合理的。

**能解释数据变化（在与之相关联的不同任务中观察到）的因素中，某些因素是跨两个或更多任务共享的。**

## 8. 提前终止

在每次验证集误差有所改善后，我们存储模型参数的副本。当训练算法终止时，我们返回这些参数而不是最新的参数。当验证集上的误差在事先指定的循环次数内没有进一步改善时，算法就会
终止。

提前终止需要验证集，这意味着某些训练数据不能被馈送到模型。为了更好地利用这一额外的数据，我们可以在完成提前终止的首次训练之后，进行额外的训练。在第二轮，即额外的训练步骤中，所有的训练数据都被包括在内。有两个基本的策略都可以用于第二轮训练过程。

1. 再次初始化模型，然后使用所有数据再次训练。在这个第二轮训练过程中，我们使用第一轮提前终止训练确定的最佳步数。此过程有一些细微之处。例如，我们没有办法知道重新训练时，对参数进行相同次数的更新和对数据集进行相同次数的遍历哪一个更好。由于训练集变大了，在第二轮训练时，每一次遍历数据集将会更多次地更新参数。
2. 保持从第一轮训练获得的参数，然后使用全部的数据继续训练。在这个阶段，已经没有验证集指导我们需要在训练多少步后终止。取而代之，我们可以监控验证集的平均损失函数，并继续训练，直到它低于提前终止过程终止时的目标值。此策略避免了重新训练模型的高成本，但表现并没有那么好。例如，验证集的目标不一定能达到之前的目标值，所以这种策略甚至不能保证终止。

**提前终止为何具有正则化效果：提前终止可以将优化过程的参数空间限制在初始参数值$\theta_0$的小邻域内。**

## 9. 参数绑定和参数共享

某些任务参数应当彼此接近，比如有两个模型执行相同的分类任务（类别相同），但输入分布稍有不同。我们有参数为$\boldsymbol{w}^{(A)}$的模型$A$和参数为$\boldsymbol{w}^{(B)}$的模型$B$。这两种模型都将输入映射到两个不同但相关的输出：$\hat{y}^{(A)} = f(\boldsymbol{w}^{(A)}, \boldsymbol{x}), \hat{y}^{(B)} = f(\boldsymbol{w}^{(B)}, \boldsymbol{x})$。

可以使用以下形式的参数范数惩罚：

$$
\Omega(\boldsymbol{w}^{(A)},\boldsymbol{w}^{(B)}) = ||\boldsymbol{w}^{(A)} - \boldsymbol{w}^{(B)}||^2_2
$$

也可以使用其他范数惩罚。

参数范数惩罚是正则化参数使其彼此接近的一种方式，而更流行的方法是使用约束：**强迫某些参数相等**。由于我们将各种模型或模型组件解释为共享唯一的一组参数，这种正则化方法通常被称为**参数共享**。例如在卷积神经网络中使用相同的卷积核，能显著减少模型所占用的内存。

## 10. 稀疏表示

参考`深度学习-优化器`和`深度学习-实际问题`以及上面部分内容，可知，稀疏表示的模型一方面增强了泛化能力，另一方面减小了模型大小以及运算开销。

## 11. Bagging和其他集成方法

参考`集成学习`

Bagging是通过结合几个模型降低泛化误差的技术，主要思想是分别训练几个不同的模型，然后让所有模型表决测试样例的输出。采用这种策略的技术被称为集成方法。

## 12. Dropout

参考`深度学习-实际问题`

一方面Dropout可以看作是廉价的Bagging方式，因为我们训练多个神经网络的开销很大，但是在每一次迭代中丢弃不同的神经元，那么自然而然地产生了不同地神经网络，从而实现了Bagging；
另一方面，Dropout可以看作是对隐藏层的噪声注入，前面已经说明了，提升了泛化性能。

## 13. 对抗训练

对抗样本，即在许多情况下，$\boldsymbol{x}$与$\boldsymbol{x}'$非常近似，人类观察者不会察觉之间的差异但是网络会做出截然相反的预测。

通过对抗训练减少原有独立同分布的测试集的错误率-在对抗扰动的训练集上训练网络。

这些对抗样本的主要原因之一是过度线性。如果一个线性函数具有许多输入，那么它的值可以常迅速地改变。如果我们用$\epsilon$改变每个输入，那么权重为$\boldsymbol{w}$的线性函数可以改变$\epsilon||\boldsymbol{w}||_1$之多，如果$\boldsymbol{w}$是高维的这会是一个非常大的数。

对抗样本也提供了一种实现半监督学习的方法。在与数据集中的标签不相关联的点$\boldsymbol{x}$处，模型本身为其分配一些标签$\hat{y}$。模型的标记$\hat{y}$未必是真正的标签，但如果模型是高品质的，那么$\hat{y}$提供正确标签的可能性很大。我们可以搜索一个对抗样本$\boldsymbol{x}'$，导致分类器输出一个标签$y'$且$y' \neq \hat{y}$。不使用真正的标签，而是由训练好的模型提供标签产生的对抗样本被称为**虚拟对抗样本**。我们可以训练分类器为$\boldsymbol{x}$和$\boldsymbol{x}'$分配相同的标签。这鼓励分类器学习一个沿着未标签数据所在流形上任意微小变化都很鲁棒的函数。驱动这种方法的假设是，不同的类通常位于分离的流形上，并且小扰动不会使数据点从一个类的流形跳到另一个类的流形上。

## 14. 切面距离、正切传播和流形正切分类器

参考`降维与度量学习`

许多机器学习通过假设数据位于低维流形附近来克服维数灾难。


