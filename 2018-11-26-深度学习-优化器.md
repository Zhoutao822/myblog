---
title: 深度学习-优化器
date: 2018-11-26 22:18:54
categories:
- deep learning
tags:
- theory
- tensorflow
- keras  
- optimizer
mathjax: true
---

参考：

> [An overview of gradient descent optimization algorithms](https://arxiv.org/pdf/1609.04747.pdf)

## 1. Tensorflow与Optimizer

Optimizer在Tensorflow框架中有两处：

1. [`tf.train.Optimizer`](https://tensorflow.google.cn/api_docs/python/tf/train/Optimizer)
2. [`tf.keras.optimizers.Optimizer`](https://tensorflow.google.cn/api_docs/python/tf/keras/optimizers)

前一个基本用在`Estimator`或者自定义模型中，后一个是`Keras`框架自带的优化器，两者几乎没有区别，在`Keras`中也可以使用`tf.train`下的优化器。

`Tensorflow`中的`Optimizer`:

1. `tf.train.AdadeltaOptimizer`
2. `tf.train.AdagradDAOptimizer`
3. `tf.train.AdagradOptimizer`
4. `tf.train.AdamOptimizer`
5. `tf.train.GradientDescentOptimizer`
6. `tf.train.MomentumOptimizer`
7. `tf.train.ProximalAdagradOptimizer`
8. `tf.train.ProximalGradientDescentOptimizer`
9. `tf.train.RMSPropOptimizer`

`Keras`中的`Optimizer`:

1. `tf.keras.optimizers.Adadelta`
2. `tf.keras.optimizers.Adagrad`
3. `tf.keras.optimizers.Adam`
4. `tf.keras.optimizers.Adamax`
5. `tf.keras.optimizers.Nadam`
6. `tf.keras.optimizers.RMSprop`
7. `tf.keras.optimizers.SGD`

<!-- more -->

## 2. 优化器原理与区别



{% asset_img optimizer1.gif 优化算法在三维空间中随时间推移而变化的可视化效果 %}


{% asset_img optimizer2.gif 优化器 %}