---
title: 卷积神经网络-coding
date: 2018-12-04 11:54:50
categories:
- Coding
tags:
- Code
- CNN
- Estimator
- Keras
- MNIST
- CIFAR-10
- Kaggle dog & cat
mathjax: true
---

## 1. 数据集说明

### 1.1 多分类图像数据集-MNIST

* 数据来源：`tf.keras.datasets.mnist.load_data`；
* 数据集形状：训练集60000个样本，测试集10000个样本，每个样本包括两个部分：图片数据和标签，每个样本的图片数据是一个$28 \times 28$的数组，即灰度图像，大小范围0~255，标签是图片对应的数字0~9，数据集中每个数字出现不是均等的，训练集`0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949`，测试集`0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009`；
* 数据集划分：在训练集中随机选出20%数据作为验证集，剩下80%用于训练，验证集用于调整超参数以及网络架构；
* 性能度量：accuracy。

### 1.2 二分类图像数据集-kaggle dog & cat

* 数据来源：[`Dogsvs.CatsRedux:KernelsEdition|Kaggle`](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)；
* 数据集形状：训练集25000个样本，测试集12500个样本，每个样本都是一张彩色图片，大小不定，训练集中图片名称即包含标签信息，测试集无标签，最后需要提交预测的结果到kaggle进行评分，预测结果为图片标签为`dog`的概率；
* 数据集划分：在训练集中随机选出20%数据作为验证集，剩下80%用于训练，验证集用于调整超参数以及网络架构；
* 性能度量：交叉熵或accuracy。

### 1.3 多分类数据集-CIFAR-10

* 数据来源：`tf.keras.datasets.cifar10.load_data`；
* 数据集形状：训练集50000个样本，测试集10000个样本，每个样本包括两个部分：图片数据和标签，每个样本的图片数据是一个$32 \times 32 \times 3$的数组，即彩色图像，大小范围0~255，标签是图片对应的种类0~9，分别对应`airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck`，数据集中每个种类出现是均等的；
* 数据集划分：在训练集中随机选出20%数据作为验证集，剩下80%用于训练，验证集用于调整超参数以及网络架构；
* 性能度量：accuracy。

<!-- more -->

## 2. Tensorflow卷积神经网络应用

参考：

> [`Github-TensorFlow-Examples`](https://github.com/aymericdamien/TensorFlow-Examples/)
> [`Tensorflow Tutorials`](https://www.tensorflow.org/tutorials/)

### 2.1 Eager模式实现手写数字分类

**数据集使用的是Tensorflow下的MNIST**

```python
#%%
# 导入未来的包，可以使用未来版本中的部分功能
from __future__ import absolute_import, print_function, division
import tensorflow as tf

# Eager模式必须手动开启，2.0版本将会是默认，Eager模型可以边运行边观察结果
tf.enable_eager_execution()
tfe = tf.contrib.eager

print('Tensorflow version: ', tf.VERSION, '\n', 'Eager mode: ', tf.executing_eagerly())

# 设置超参数
learning_rate = 1e-4
num_steps = 20000
batch_size = 64
display_step = 100

num_classes = 10

# 获取数据
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

print('train size:', x_train.shape, y_train.shape)
print('test size:', x_test.shape, y_test.shape)

# 这里需要reshape图片，原始图片是28*28，这里转换成28*28*1，标签需要转换成onehot变量便于后面计算交叉熵，axis=-1，可以使标签转换成m*depth的形状
x_train = tf.reshape(tf.cast(x_train, tf.float32), shape=[-1, 28, 28, 1])
x_test = tf.reshape(tf.cast(x_test, tf.float32), shape=[-1, 28, 28, 1])
y_train = tf.one_hot(y_train, depth=10, axis=-1)
y_test = tf.one_hot(y_test, depth=10, axis=-1)

# 构造输入的dataset，注意Eager模式需要使用tfe调用迭代器Iterator
dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(batch_size)
dataset_iter = tfe.Iterator(dataset)

# 定义一个CNN类，Eager模式需要继承自tfe.Network，推荐废弃，使用keras取代
class CNN(tfe.Network):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv2d_1 = self.track_layer(
            tf.layers.Conv2D(32, 5, padding='SAME', activation='relu'))
        self.conv2d_2 = self.track_layer(
            tf.layers.Conv2D(64, 5, padding='SAME', activation='relu'))
        self.maxpool = self.track_layer(
            tf.layers.MaxPooling2D(2, 2, padding='SAME'))
        self.flatten = self.track_layer(
            tf.layers.Flatten()) 
        self.fclayer = self.track_layer(
            tf.layers.Dense(1024, activation='relu'))
        self.dropout = self.track_layer(
            tf.layers.Dropout(0.5))
        self.out_layer = self.track_layer(
            tf.layers.Dense(num_classes))
    
    def call(self, x, training=True):
        x = self.conv2d_1(x)
        x = self.maxpool(x)
        x = self.conv2d_2(x)
        x = self.maxpool(x)
        x = self.flatten(x)
        x = self.fclayer(x)
        if training:
            x = self.dropout(x)
        return self.out_layer(x)

cnn = CNN()

# 定义损失函数，softmax_cross_entropy_with_logits_v2包含两步，首先计算softmax，再计算交叉熵，需要注意
def loss_fn(inference_fn, inputs, labels):
    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(
        logits = inference_fn(inputs), labels = labels))

# 定义计算准确率的函数，这里通过argmax取softmax中最高的那个概率的索引，也就是对应的数字
def accuracy_fn(inference_fn, inputs, labels, training):
    prediction = tf.nn.softmax(inference_fn(inputs, training))
    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))
    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))

# Eager模式的梯度计算方式implicit_gradients
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
grad = tfe.implicit_gradients(loss_fn)

average_loss = 0.
average_acc = 0.

for step in range(num_steps):
    try:
        d = dataset_iter.next()
    except StopIteration:
        dataset_iter = tfe.Iterator(dataset)
        d = dataset_iter.next()

    x_batch = d[0]
    y_batch = tf.cast(d[1], tf.int64)

    batch_loss = loss_fn(cnn, x_batch, y_batch)
    average_loss += batch_loss

    batch_accuracy = accuracy_fn(cnn, x_batch, y_batch, False)
    average_acc += batch_accuracy

    if step == 0:
        print("Initial loss= {:.6f}".format(average_loss))

    # Eager模式参数梯度下降
    optimizer.apply_gradients(grad(cnn, x_batch, y_batch))

    if (step + 1) % display_step == 0 or step == 0:
        if step > 0:
            average_loss /= display_step
            average_acc /= display_step
        print("Step:", '%04d' % (step + 1), " loss=",
              "{:.6f}".format(average_loss), " accuracy=",
              "{:.4f}".format(average_acc))
        average_loss = 0.
        average_acc = 0.
        
test_acc = accuracy_fn(cnn, x_test, y_test, False)
print('Testset accuracy: {:.4f}'.format(test_acc))
```

训练时间有点长

`Testset accuracy: 0.9916`

### 2.2 Keras实现手写数字分类

使用Keras一方面可以简化代码，比如神经网络模型构建过程简化，Dropout层自动判断属于train阶段还是evaluate阶段，另一方面输出结果自动显示，不需要手动print。所以，推荐使用keras或者其他自定义estimator完成机器学习任务。

```python
from __future__ import absolute_import, print_function, division
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers


print('Tensorflow version: ', tf.VERSION)

learning_rate = 1e-4
steps_per_epoch = 1000 # 一般等于 样本总数/batch_size
batch_size = 64
epochs = 20 # 训练轮数，即循环使用整个数据集的次数

num_classes = 10

# 这里缩放了图像的灰度值，为了加速收敛，为了满足model的输入形状，reshape为(28,28,1)，这里不需要将标签转换为onehot类型
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train , x_test = x_train / 255. , x_test / 255.
x_train = tf.reshape(x_train, [-1, 28, 28, 1])
x_test = tf.reshape(x_test, [-1, 28, 28, 1])
print('train size:', x_train.shape, y_train.shape)
print('test size:', x_test.shape, y_test.shape)

# 构建dataset，增加了repeat，是为了可以循环使用数据集
dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(batch_size).repeat()

# keras构建模型的方式就很简单了，直接选择需要的layer堆叠起来
model = keras.Sequential([
    # Conv2D卷积层，需要定义filters，kernel_size，strides，padding，activation，首层还需要input_shape，必须是(height, width, channel)
    layers.Conv2D(32, 5, padding='SAME', activation='relu', input_shape=(28, 28, 1)),
    # MaxPool2D池化层，需要定义pool_size，strides，padding
    layers.MaxPool2D(2, padding='SAME'),
    layers.Conv2D(64, 5, padding='SAME', activation='relu'),
    layers.MaxPool2D(2, padding='SAME'),

    layers.Flatten(),
    layers.Dense(1024, activation='relu'),
    # Dropout丢弃层，这里的0.5是丢弃率，有些函数里是保留率，需要注意
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])

# 设置优化器optimizer，损失函数loss，这里使用sparse_categorical_crossentropy是因为label为数字，categorical_crossentropy对应label为onehot，以及evaluate时使用的准则metrics
model.compile(
    optimizer=tf.keras.optimizers.Adam(lr=learning_rate),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
# summary会展示模型的结构，包括每一层参数个数，每一层输入形状
model.summary()

model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch)

model.evaluate(x_test, y_test, steps=1)
```
使用CPU训练大概一个半小时

> loss: 0.0226
> accuracy: 0.9925

### 2.3 基于Keras使用预训练的网络实现猫狗识别

首先导入需要的库，这里我们可以直接使用keras自带的已经训练好的网络，比如VGG16

```python
#%%
from __future__ import division
from __future__ import absolute_import
from __future__ import print_function

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras import layers
from tensorflow.keras import Sequential 

import tensorflow as tf
import pandas as pd
import numpy as np
import os # 用于文件路径
import shutil # 用于文件复制

print('Tensorflow version: ', tf.VERSION)
```

然后设置一些可能会用到的超参数，这里训练集25000张图片等于`batch_size * steps_per_epoch`，以及图片长宽

```python
learning_rate = 1e-4
batch_size = 20
epochs = 30
steps_per_epoch = 1250
img_height = 150
img_width = 150
img_channels = 3
```

为了测试代码，我们先不使用整个数据集，而是从原始数据集中划分出一小部分数据进行测试（需要修改上面的超参数），在确定代码无误后，我们需要修改这部分代码，因为训练集是完整的train文件夹

```python
# 我们从原始的train文件夹下，分别选择猫和狗的前2000张作为训练集，之后的500作为验证集
base_dir = 'C:/Users/Admin/Downloads/dogvscat'
original_dir = os.path.join(base_dir, 'train')

# 选择的图片存放在small文件夹下
train_dir = os.path.join(base_dir, 'small_train')
eval_dir = os.path.join(base_dir, 'small_eval')
test_dir = os.path.join(base_dir, 'test')

if not os.path.exists(train_dir):
    os.mkdir(train_dir)
    os.mkdir(eval_dir)

for i in range(2500):
    name = 'cat.{}.jpg'.format(i)
    src = os.path.join(original_dir, name)
    if i < 2000:
        dst = os.path.join(train_dir, name)
    else:
        dst = os.path.join(eval_dir, name)
    shutil.copyfile(src, dst) # 复制图片

for i in range(2500):
    name = 'dog.{}.jpg'.format(i)
    src = os.path.join(original_dir, name)
    if i < 2000:
        dst = os.path.join(train_dir, name)
    else:
        dst = os.path.join(eval_dir, name)
    shutil.copyfile(src, dst)
```

准备输入数据，包括两部分，一个是图片绝对路径，一个是标签（dog为1，cat为0）

```python
# 定义一个shuffle函数，使用np.random.permutation生成随机序列，保证路径与标签一一对应
def unison_shuffled_copies(a, b):
    a = np.array(a)
    b = np.array(b)
    assert len(a) == len(b)
    p = np.random.permutation(len(a))
    return a[p], b[p]

files = os.listdir(train_dir)
train_files = [os.path.join(train_dir, name) for name in files]
train_labels = np.array(['dog' in name for name in files]).astype(np.float)
train_files, train_labels = unison_shuffled_copies(train_files, train_labels)

files = os.listdir(eval_dir)
eval_files = [os.path.join(eval_dir, name) for name in files]
eval_labels = np.array(['dog' in name for name in files]).astype(np.float)
eval_files, eval_labels = unison_shuffled_copies(eval_files, eval_labels)

# 这个地方应该是bug，Tensorflow version 1.12.0，keras的model使用predict需要target和label，而label对于需要预测的数据来说无意义，随便设置为-1
files = ['{}.jpg'.format(i) for i in range(1, 12501)]
test_files = [os.path.join(test_dir, name) for name in files]
test_labels = np.array([-1] * len(files)).astype(np.float) # 理论上不需要这个
```

我们需要把图片绝对路径转换为图片数据，在输入函数中解决

```python
def image_input_fn(filenames, labels=None, shuffle=False, repeat_count=1, batch_size=1):
    # 读取数据，解码，resize图片，归一化（这里只是除以255）
    def _read_img(filename, label=None):
        img_raw = tf.read_file(filename)
        img = tf.image.decode_image(img_raw, channels=3)
        img.set_shape([None, None, None]) # decode_image需要，decode_jpeg不需要
        img = tf.image.resize_images(img, [img_height, img_width])
        img = tf.divide(img, 255.)
        img.set_shape([img_height, img_width, img_channels])
        # 理论上测试数据集的label为空，但是keras不允许，对应上面的bug
        if label is None:
            return img
        else:
            return img, label
    if labels is None:
        dataset = tf.data.Dataset.from_tensor_slices(filenames)
    else:
        dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
    dataset = dataset.map(_read_img)
    if shuffle:
        dataset = dataset.shuffle(2000)
    dataset = dataset.batch(batch_size).repeat(repeat_count)
    return dataset
```

定义训练模型，我这里定义了两个注释掉的部分是使用预训练VGG16，VGG16的参数不变，仅训练连接层的参数，这样需要的内存比较小；没有注释的部分是自定义的model

```python
# vgg16 = VGG16(
#     weights='imagenet',
#     include_top=False,
#     input_shape=(img_height, img_width, img_channels))
# model = Sequential([
#     vgg16,
#     layers.Flatten(),
#     layers.Dropout(0.5),
#     layers.Dense(1, activation='sigmoid')
# ])
# vgg16.trainable = False

model = Sequential([
    layers.Conv2D(32, 5, 2, padding='SAME', activation='relu', input_shape=(img_height, img_width, img_channels)),
    layers.MaxPool2D(strides=2, padding='SAME'),
    layers.Dropout(0.3),

    layers.Conv2D(64, 5, 2, padding='SAME', activation='relu'),
    layers.MaxPool2D(strides=2, padding='SAME'),
    layers.Dropout(0.3),
    
    layers.Conv2D(128, 5, 2, padding='SAME', activation='relu'),
    layers.MaxPool2D(strides=2, padding='SAME'),
    layers.Dropout(0.3),

    layers.Flatten(),
    layers.Dense(1024, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')
])

model.summary()

# 这里使用Adam优化器，对比了RMSProp，Adam收敛速度快一些
model.compile(
    optimizer=tf.train.AdamOptimizer(learning_rate),
    loss='binary_crossentropy',
    metrics=['acc'])

# 这里调用了callback，保存checkpoint，monitor和save_best_only保证了只在val_loss减小的情况下保存模型参数，period指定了保存的时机，每5个epoch保存一次
MODEL_DIR = './model/'
checkpoint_path = MODEL_DIR + "cp-{epoch:04d}.ckpt"
cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, 
                                                monitor='val_loss',
                                                save_best_only=True,
                                                verbose=1, 
                                                save_weights_only=True, 
                                                period=5)
```

开始训练，测试，保存最终结果

```python
# 中途停止可以使用下面这行重新加载参数，cp-0015视具体情况修改
# model.load_weights('./model/cp-0015.ckpt')

model.fit(
    image_input_fn(
        train_files, 
        train_labels,
        shuffle=True, 
        repeat_count=epochs,
        batch_size=batch_size), 
    validation_data=image_input_fn(
        eval_files,
        eval_labels,
        shuffle=False,
        repeat_count=epochs,
        batch_size=50), # batch_size * validation_steps应当等于验证集大小
    epochs=epochs,
    steps_per_epoch=steps_per_epoch,
    validation_steps=20,
    callbacks=[cp_callback])

result = model.predict(
    image_input_fn(
        test_files,
        test_labels, # 这个地方是个bug
        shuffle=False,
        batch_size=50), 
        steps=250) # batch_size * steps应当等于测试集大小，这里调整可以减小内存需要

# 根据kaggle的经验，限制结果在[0.005, 0.995]之间有助于增加分数
path = './submission1.csv'
counter = range(1, len(result) + 1)
result = np.array(result, np.float)
result = np.squeeze(result)

def limit(x):
    if x < 0.005:
        return 0.005
    elif x > 0.995:
        return 0.995
    else:
        return x

df = pd.DataFrame({'id': counter, 'label': result})
df['label'] = df['label'].map(limit)

file = df.to_csv(path_or_buf=None, index=None)
with tf.gfile.Open(path, 'w') as f:
    f.write(file)

print('Mission Accomplished!')
```

在train完整训练集上，我们使用自定义model训练40轮后得到的分数为

> 0.24594

在train完整训练集上，我们使用VGG16训练10轮后得到的分数为（还有进步空间，前10%大约0.04左右，差距很大）

> 0.21975

但是使用VGG16时有一个明显的问题，设置VGG16模型的参数不参与训练，但是每一次迭代都在计算这一层，也就是说我们浪费了很多时间重复计算。所以接下来我们考虑先使用VGG16或者其他模型对训练集图片生成新的特征向量，再对特征向量建立输出，这样就只需要计算一次VGG16层。

### 2.4 Tensorflow深入-CIFAR10识别

参考：

> [高级卷积神经网络](https://www.tensorflow.org/tutorials/images/deep_cnn)
> [Kaggle猫狗大战准确率Top 2%webapp部署](https://www.jianshu.com/p/1bc2abe88388)
> [CIFAR-10 ResNet](https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator)

**首先分析一下Google官网的CIFAR-10源码**











